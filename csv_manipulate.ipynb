{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352176f-1d0d-4354-9f9e-0e4edef6d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd18b0-ec03-4368-af38-036719eb1def",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = pd.read_csv(\"SBIC.v2.agg.trn.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72a900-bb79-4ccd-83b1-f654bc6acfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a13f8-52ff-4465-8d5b-e7cd1a7d6090",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Manipulating the CSV file so that we only use the columns specified by Maarten\n",
    "- post [CLS] offensiveYN [GRP] group [STE] implications [END]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926b13d-707f-4880-9fd7-986f44ab675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = training_csv.drop([\"dataSource\", \"offensiveYN\", \"sexYN\", \"intentYN\", \"targetCategory\"], axis=1, index=None)\n",
    "training_csv.columns = [\"post\", \"group\", \"implications\", \"whoTarget\", \"offensiveYN\"]\n",
    "training_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c351b-dbf4-414d-b611-43dd8d03a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fed8e3-fb59-4912-8397-7688b72a665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_csv[\"group\"] = training_csv[\"group\"].apply(lambda label: \"NaN\" if label=='[]' else label)\n",
    "training_csv[\"offensiveYN\"] = training_csv[\"offensiveYN\"].apply(lambda label: \"[OffN]\" if label==1 else \"[OffY]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c1383-25a6-4c48-9944-7d52cd6fb2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_csv[\"offensiveYN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23106b3-28b5-404f-a19c-5690ce023045",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv[\"post\"] = training_csv[\"post\"].apply(lambda label: \"[BOS]\" + label + \"[CLS]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88242c8-7375-4917-992c-70956a8147c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d1987-29b4-4243-bf5c-cada06c012af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNewLine(i, group):\n",
    "    copy_df = training_csv.copy(deep=True)\n",
    "    copy_df.append(copy_df.loc[[i]])\n",
    "    copy_df.loc[[len(training_csv)-1]][\"implications\"] = group[len(group)-1]\n",
    "    del group[-1]\n",
    "    copy_df.loc[i,\"implications\"] = str(group)\n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ba121-e578-4181-8f2c-9c4f162018be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "#one implication per line\n",
    "# if > 1 implication, copy entire line, put on end, change group\n",
    "list_implications = []\n",
    "list_group = []\n",
    "for i in training_csv.index:\n",
    "    list_val = ast.literal_eval(training_csv.loc[[i]][\"implications\"].values[0])\n",
    "    if (len(list_val) > 1):\n",
    "        while (len(list_val) > 1):\n",
    "            training_csv = createNewLine(i, list_val)\n",
    "            list_val = ast.literal_eval(training_csv.loc[[i]][\"implications\"].values[0])\n",
    "    list_group.append(\",\".join(map(str, ast.literal_eval(training_csv.loc[[i]][\"group\"].values[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169d640-0a0d-4e60-b7fc-6bdee6f58abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_csv[\"implications\"] = list_implications\n",
    "training_csv[\"group\"] = list_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1758d8-ecfa-498e-b014-34b5b57b55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv\n",
    "#do final pass over the implications and get rid of list format\n",
    "for i in training_csv.index:\n",
    "    list_implications.append(\",\".join(map(str, ast.literal_eval(training_csv.loc[[i]][\"implications\"].values[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393fc7d-ebc4-465f-978e-5e152d8c8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv[\"implications\"] = list_implications\n",
    "training_csv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbf88c5a-91ff-41f7-b53b-3b686d6dbba6",
   "metadata": {},
   "source": [
    "#training_csv[\"group\"] = training_csv[\"group\"].apply(lambda label: \"NaN\" if label=='[]' else label)\n",
    "training_csv[\"offensiveYN\"] = training_csv[\"offensiveYN\"].apply(lambda label: \"[OffN]\" if label==1 else \"[OffY]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368813b-943d-4ab0-8791-3b72f85fa359",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_csv[\"implications\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd6e51-046c-43ae-b477-3af07b25ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for i in training_csv.index:\n",
    "    if (training_csv.loc[[i]][\"whoTarget\"].values[0] == 0.0 and training_csv.loc[[i]][\"offensiveYN\"].values[0] == \"[OffY]\"):\n",
    "        final_list.append(\"[IND] [END]\")\n",
    "    elif (training_csv.loc[[i]][\"offensiveYN\"].values[0] == \"[OffN]\"):\n",
    "        final_list.append(\" [END]\")\n",
    "    else:\n",
    "        final_list.append(\"[GRP] \" + str(training_csv.loc[[i]][\"group\"].values[0]))# + \" [STE] \" + str(training_csv.loc[[i]][\"implications\"].values[0]) + \" [END]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be6308-5c00-4707-aa72-b9a9c858be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv[\"implications\"] = training_csv[\"implications\"].apply(lambda label: \"[STE] \" + label + \" [END]\" if len(label)>0 else label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefb5ce-787e-44da-9ba7-8ed52d987f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv[\"group\"] = final_list\n",
    "training_csv = training_csv.drop([\"whoTarget\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b97a0d-9fae-46a5-b185-9d65f841752a",
   "metadata": {},
   "source": [
    "[BOS] I hate all gay cause they are bad [CLS] [OffY] [GRP] gay men [STE] implies that gays are bad [END] \\\n",
    "[BOS] You're a moron [CLS] [OffY] [IND] [END] \\\n",
    "[BOS] I cannot stand women sport announcers [CLS] [OffY] [GRP] Women [STE] Women aren't knowledgeable about sports [END]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d099fc25-c4c4-4167-80a4-d5a36cbebfe1",
   "metadata": {},
   "source": [
    "post [CLS] offensiveYN [GRP] group [STE] implications [END]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59bb4c77-9d2a-43ff-933f-0d90ec254ba2",
   "metadata": {},
   "source": [
    "final_list = []\n",
    "final_input = []\n",
    "for i in training_csv.index:\n",
    "    final_input.append(\"[BOS] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [CLS] \")\n",
    "    if (training_csv.loc[[i]][\"whoTarget\"].values[0] == 0.0 and training_csv.loc[[i]][\"offensiveYN\"].values[0] == \"OffY\"):\n",
    "        print(i)\n",
    "        print(\"[\" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \n",
    "                      \"] \" + \"[IND] \" \"[END]\")\n",
    "        final_list.append(\"[\" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \n",
    "                      \"] \" + \"[IND] \" \"[END]\")\n",
    "    elif (training_csv.loc[[i]][\"offensiveYN\"].values[0] == \"OffN\"):\n",
    "        final_list.append(\"[\" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \n",
    "                      \"]\" + \" [END]\")\n",
    "    else:\n",
    "        final_list.append(\"[\" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \n",
    "                      \"] \" + \"[GRP] \" + str(training_csv.loc[[i]][\"group\"].values[0]) + \" [STE] \" + str(training_csv.loc[[i]][\"implications\"].values[0]) + \" [END]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8007c-e78d-40e7-ab90-dfbaad865fd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# scramble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb5c32-2814-44e4-8dd9-43407d7214fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scramble_output = []\n",
    "final_scramble_input = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca707e-f518-4aad-ac03-6e98a3b65643",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv.loc[[2]].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e0cdb-82de-46ca-b388-884b3f22b809",
   "metadata": {},
   "source": [
    "### When scrambling, have the same posts multiple times with different inputs outputs scrambled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59cccf9-6af6-4d44-b0d5-a1abb3e272be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f884eec0-b15c-4e64-a31f-94fbae337ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "for i in range(0, len(training_csv.index)):\n",
    "    # create 4 versions of each post in scrambled order (more data)\n",
    "    for i in range(0,4):\n",
    "        # create a list of all things to append to either input or output in the dataframe, append whatevers left to output\n",
    "        toAppend = list(filter(lambda item: item.strip(), training_csv.loc[[i]].values.tolist()[0]))\n",
    "        # randomly decide how much is appended to the output and how much for the input (at least one thing has to be in the input/output\n",
    "        appendNum = random.randint(1, len(toAppend)-1)\n",
    "        # loop by appendnum\n",
    "        # new list er input and output, make into a sentence later\n",
    "        listApp = []\n",
    "        for i in range(0, appendNum) :\n",
    "            # randomly decide what to append to the output and what to append to the input\n",
    "            i = random.randint(0, len(toAppend)-1)\n",
    "            value = toAppend.pop(i)\n",
    "            listApp.append(value)\n",
    "        final_scramble_input.append(listApp)\n",
    "        # whatever is left goes to output\n",
    "        final_scramble_output.append(toAppend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8f057-6111-4c0f-ae0f-a0450dd86734",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_scramble_input) == 4 * len(training_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70f27d-85c1-49b5-af66-be45ca7a035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scramble_input[0]\n",
    "final_scramble_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654b5235-a4b4-41a2-ac16-d71dd0e71aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension - make each entry into one string\n",
    "string_scramble_input = [\"\".join(f).strip() for f in final_scramble_input]\n",
    "string_scramble_output = [\"\".join(f).strip() for f in final_scramble_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e978738-5daf-46e5-855f-bbcb434b4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_scramble_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0accaa-cf84-4d52-90b2-bd25d2ff013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c939b5-77ec-46c4-9aec-af6c2d5a6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"input\"] = string_scramble_input\n",
    "final_df[\"output\"] = string_scramble_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53a022-5b7c-43c1-9326-8f1f036c73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_scramble_input[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326d5bb-29c4-469e-9db2-152f51eaa00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_scramble_output[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1421d4f-f337-4089-8253-be057636d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"SBIC.dev.scrambled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a126bb-1c13-4ee5-b511-d5b91f1e8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819329db-8df9-43ab-ac96-c25a52407211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://homes.cs.washington.edu/~msap/pdfs/sap2020socialbiasframes.pdf and \n",
    "# https://arxiv.org/pdf/2109.05322v1.pdf\n",
    "sample_input = []\n",
    "samples = [\"Kendrick just dropped the coldest video of all fucking time\", \"What a fucking stupid bitch shut the fuck up already\",\n",
    "           \"need to fuck sum bad , I got some pressure built up :P\", \"I take a bitch home give her long dick\", \n",
    "           \"You annoyed me every day for months you’re a fucking moron\", \n",
    "           \"My problem with Korean artists: I dont know how to pronounce your name I can’t hanggul to save my life\",\n",
    "           \"I’ll continue this thread till non-lifting fags stop lifting like idiots at the gym... Which is never.\",\n",
    "           \"I thought drugs were the only things black people could shoot up Boy was I wrong\",\n",
    "           \"white revolution is the only solution\",\n",
    "           \"yes you are fine in a white majority country. how is mexico doing these days? people come here because you couldn’t build it.\",\n",
    "           \"black people only seem to thrive in white countries. how strange\", \n",
    "           \"soon white people will not be a majority anywhere. you believe\",\n",
    "           \"muslims are always wanting to kill someone! its their duty to kill the infidel.\",\n",
    "           \"oh how i wish a man with a gun was there! wake up white people! they hate us\"\n",
    "        ]\n",
    "for sample in samples:\n",
    "    sample_input.append(\"[BOS] \" + sample + \" [CLS] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ba033-a9e7-46ed-aee6-1a86b6a0dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9780f6-9280-4f2e-bb4d-c71ca5b76445",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame()\n",
    "sample_df[\"input\"] = sample_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489ab0d-9578-4f7e-9a46-8fecdff42436",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv(\"samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3b82c-8673-426b-8c2e-4e9887e345ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45eba6-f615-45e5-a8a8-ba9457abc634",
   "metadata": {},
   "source": [
    "- draw conclusions about what needs to happen, what are pitfalls/missing, more data needed? Which of the categories from latent hate they are (best guess, pick samples to show them)\n",
    "- look at stereotypes, and guess what the model may need\n",
    "- create demo to help with playing with it\n",
    "- grab data that has already been released\n",
    "- dynahate (subtle hatred)\n",
    "- retrain group and append group to input and only guess stereotype\n",
    "- input and output is whole string, take fraction as input and remain as output, train model on all forms of input (when using at inference time, it generates what you want)\n",
    "- scramble method (try both models, see what happens)\n",
    "- take examples from social boas, implicit hate, dynsahate, see what the model generates/compare to actual data, derive insights from this\n",
    "- paper that maarten shared (they - how would model pick up on it)\n",
    "- read papers in chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91febe40-0c3f-4aa0-ada0-25440bc3225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec717a4-c1bd-40c3-b5e9-c40102c319fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(\"SBIC.dev.1.csv\")[\"output\"]\n",
    "#y_test = y_test.drop([\"dataSource\", \"offensiveYN\", \"sexYN\", \"intentYN\", \"targetCategory\"], axis=1, index=None)\n",
    "#y_test.columns = [\"post\", \"group\", \"implications\", \"whoTarget\", \"offensiveYN\"]\n",
    "#y_pred = pd.read_csv(\"predictions_scrambled.csv\", index_col=0)[\"Generated Text\"].values #TODO: fix path if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f3ccb-c0ae-44f3-9cfb-ae7ba23b4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe56df0-6a0b-4087-b81b-76daf0b2e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reg expressions to split into offy, group, etc. - calculate accuracy on each\n",
    "# tokens = ['[BOS]', '[CLS]', '[OFFY]', '[OFFN]', '[IND]', '[STE]', '[END]', '[GRP]']\n",
    "res = []\n",
    "# split on parenthesis\n",
    "for i in range(0, len(y_test)):\n",
    "    res.append(list(filter(lambda x: x != \"\", [sentence.strip() for sentence in\n",
    "                                                    y_test[i].replace(\"<pad>\", '').replace(\"[\", '').replace(\"boo\",'')\n",
    "                                                    .replace(\"grp\", '').replace(\"ste\", '').replace(\"eoo\", '')\n",
    "                                                    .split(']')])))\n",
    "   # res.append(list(filter(lambda x: x != \"\", [sentence.strip() for sentence in y_pred[i].replace(\"<pad>\", '').replace(\"[\", '').replace(\"END\", '').replace(\"STE\", '').replace(\"GRP\", '').split(']')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a34f0-ca63-4f70-96bd-c3dae086d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #TODO: add all characters to re split re.split(\"[]+\")\n",
    "# binary acc for offn/y, ignore group/implication if OffN\n",
    "res = pd.DataFrame(res)\n",
    "res[0] = res[0].apply(lambda label: 1 if label==\"OffN\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61676454-9344-4cb1-9b8c-37f513f0999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f59d3-4dc0-4f10-bbd1-f9634ec9a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_int = sum(res[0].values == y_test[\"offensiveYN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b812ef6-2b52-436b-ab0e-2e2fbedee409",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Accuracy of OFFy vs OFFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0855ba-3c52-4598-8fc2-6b98764aa525",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_int/len(res[0].values == y_test[\"offensiveYN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b2554-f438-48bc-aac4-5f33e4b5fb62",
   "metadata": {
    "tags": []
   },
   "source": [
    "# F1 Score of OFFy vs OFFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665451d-d6f5-436a-8faf-2b45802492f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test[\"offensiveYN\"].values, res[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b330b2-beb3-4800-9280-e2079acdbecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77be638-3d13-4b7a-a06e-8c128b2e5798",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Qualitative Analysis - how does the models groupings relate to the original (maybe use contains?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae9ccc0-37f8-45fa-bbe5-6fddd1fc3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does it match any of the groups from the original \n",
    "# ngram - BLEU score nltk package to use \n",
    "# exact match and bleu score\n",
    "match = []\n",
    "for i in range(0,len(res)):\n",
    "    if (list(y_test[\"offensiveYN\"].values)[i] == 0):\n",
    "        res_val = str(list(res[1].values)[i])\n",
    "        y_test_val = list(y_test[\"group\"].values)\n",
    "        match.append(any(res_val in s for s in y_test_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e7be6-3ee8-4117-bffb-b1188b38bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(match) / len(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbb311-8ec2-4804-9973-7e585541c831",
   "metadata": {
    "tags": []
   },
   "source": [
    "# New Scrambler Method as Per last meeting\n",
    "- need to overrepresent offensive samples and have more structure with the tokens so the model learns\n",
    "- create each kind of scramble for each input\n",
    "#### Most important:\n",
    "1) generate stereotype given just post\n",
    "2) generate stereotype given post, group, and offensiveness\n",
    "3) generate post given group, sterotype, and offensiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39fdf52-0c60-466b-b541-291557de314e",
   "metadata": {},
   "source": [
    "Making three kinds of scrambles:\n",
    "1) regular, with new tokens\n",
    "2) full scramble, with new tokens\n",
    "3) important scramble, with new tokens"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a881e8df-548e-4ec0-9c06-4e81d62ac8cf",
   "metadata": {},
   "source": [
    "[offY] [grp/ind] group [ste] stereotype [CLS] [bos] post [eos]\n",
    "[offY] [grp/ind] group [CLS] post [ste] stereotype [eos] \n",
    "[offY] [grp/ind] group [CLS] [ste] stereotype [bos] post [eos] \n",
    "[offY] [ste] stereotype [CLS] [bos] post [grp/ind] group [eos] \n",
    "[offY] [CLS] [bos] post [ste] stereotype [grp/ind] group [eos]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b0fda16-1085-412d-80bc-531707e4c903",
   "metadata": {},
   "source": [
    "[boi] [offY] [grp/ind] group [ste] sterotype [eoi] [boo] stereotype [eoo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25c63b-e70a-4eb9-b4e5-b19e78259ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = pd.read_csv(\"SBIC.v2.agg.dev.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46d3e3-613f-4b4e-877a-3c55159de705",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05de8d-434c-419a-b4be-a65b536e8db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = training_csv.drop([\"dataSource\", \"offensiveYN\", \"sexYN\", \"intentYN\", \"targetCategory\"], axis=1, index=None)\n",
    "training_csv.columns = [\"post\", \"group\", \"implications\", \"whoTarget\", \"offensiveYN\"]\n",
    "training_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8b18c-5337-4738-b378-9771d503527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_csv[\"group\"] = training_csv[\"group\"].apply(lambda label: \"NaN\" if label=='[]' else label)\n",
    "training_csv[\"offensiveYN\"] = training_csv[\"offensiveYN\"].apply(lambda label: \"[OffN]\" if label==1 else \"[OffY]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f651f34-0ed0-4c79-b69d-a5db334e9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNewLine(i, group):\n",
    "    copy_df = training_csv.copy(deep=True)\n",
    "    copy_df.append(copy_df.loc[[i]])\n",
    "    copy_df.loc[[len(training_csv)-1]][\"implications\"] = group[len(group)-1]\n",
    "    del group[-1]\n",
    "    copy_df.loc[i,\"implications\"] = str(group)\n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea9532-e3cf-459b-acbe-fc472cb707c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "#one implication per line\n",
    "# if > 1 implication, copy entire line, put on end, change group\n",
    "list_implications = []\n",
    "list_group = []\n",
    "for i in training_csv.index:\n",
    "    list_val = ast.literal_eval(training_csv.loc[[i]][\"implications\"].values[0])\n",
    "    if (len(list_val) > 1):\n",
    "        while (len(list_val) > 1):\n",
    "            training_csv = createNewLine(i, list_val)\n",
    "            list_val = ast.literal_eval(training_csv.loc[[i]][\"implications\"].values[0])\n",
    "    list_group.append(\",\".join(map(str, ast.literal_eval(training_csv.loc[[i]][\"group\"].values[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098aad0-dad7-4b64-9d3b-aae0defd27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_csv[\"implications\"] = list_implications\n",
    "training_csv[\"group\"] = list_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c2e1a-2d22-4d11-b11e-f1757a4f4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv\n",
    "#do final pass over the implications and get rid of list format\n",
    "for i in training_csv.index:\n",
    "    list_implications.append(\",\".join(map(str, ast.literal_eval(training_csv.loc[[i]][\"implications\"].values[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5d9fb-109a-4370-893b-31930fdd84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv[\"implications\"] = list_implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd14535a-5475-42c9-a7d5-ca0bcd627750",
   "metadata": {},
   "source": [
    "## 1) Regular"
   ]
  },
  {
   "cell_type": "raw",
   "id": "952aae66-0213-47b1-8140-9314f383fa2b",
   "metadata": {},
   "source": [
    "[boi] post [eoi] [boo] [offY] [grp/ind] group [ste] stereotype [eoo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccfdefd-f98c-4355-a729-4c3f79f41195",
   "metadata": {},
   "source": [
    "# 50/50 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811321e-593d-453a-ba59-c3cf98d869f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa6494-f5f9-4dd2-9985-9a97bf6d058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "offY_df = training_csv.where(training_csv[\"offensiveYN\"] == \"[OffY]\").dropna(subset=['offensiveYN'])\n",
    "num_offY = len(offY_df.index)\n",
    "offN_df = training_csv.where(training_csv[\"offensiveYN\"] == \"[OffN]\").dropna(subset=['offensiveYN']).sample(n=num_offY).reset_index()\n",
    "fifty_df = pd.concat([offY_df, offN_df])\n",
    "fifty_df = fifty_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b7742-7fea-46cb-b702-eaecf161d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881100a-33dc-42d6-a372-e285cd2c9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = fifty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2299f-81c7-46e6-9dfe-107026ecbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_input = []\n",
    "final_output = []\n",
    "for i in training_csv.index:\n",
    "    final_input.append(\"[boi] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [eoi]\")\n",
    "    if (training_csv.loc[[i]][\"whoTarget\"].values[0] == 0.0 and training_csv.loc[[i]][\"offensiveYN\"].values[0] == \"[OffY]\"):\n",
    "        print(\"here\")\n",
    "        final_output.append(\"[boo] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \"[ind] [eoo]\")\n",
    "    elif (training_csv.loc[[i]][\"offensiveYN\"].values[0] == \"[OffN]\"):\n",
    "        final_output.append(\"[boo] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \" [eoo]\")\n",
    "    else:\n",
    "        final_output.append(\"[boo] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \" [grp] \" + \n",
    "                          str(training_csv.loc[[i]][\"group\"].values[0]) + \" [ste] \" + \n",
    "                          str(training_csv.loc[[i]][\"implications\"].values[0]) + \" [eoo]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98442c-12a2-458e-b1b8-2f21218f9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d949136-0bce-42b7-b560-8ab35f3ee749",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_df[\"input\"] = final_input\n",
    "regular_df[\"output\"] = final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda627e-6080-4cc7-b3c7-2c7a4da488fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a34678-3352-4d78-b58b-d2a5c416f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_df.to_csv(\"SBIC.trn.2.5050.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49fe8d1-68da-44a4-9551-f039000e3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv(\"predictions_regular.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae947a-9b8a-4143-9677-df3a2bfc663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d148bd0-f962-4dbe-a249-59d16ce5ec01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2) Full Scramble"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30b2b6a4-aebb-4e7a-b617-2aadc3a48e59",
   "metadata": {},
   "source": [
    "[offY] [grp/ind] group [ste] stereotype [CLS] [bos] post [eos]\n",
    "[offY] [grp/ind] group [CLS] post [ste] stereotype [eos] \n",
    "[offY] [grp/ind] group [CLS] [ste] stereotype [bos] post [eos] \n",
    "[offY] [ste] stereotype [CLS] [bos] post [grp/ind] group [eos] \n",
    "[offY] [CLS] [bos] post [ste] stereotype [grp/ind] group [eos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89562b-d51b-4269-ae56-151087c6fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_input = []\n",
    "final_output = []\n",
    "for i in training_csv.index:\n",
    "    # If it isn't offensive, do the usual (from \"regular\" scramble)\n",
    "    if (training_csv.loc[[i]][\"offensiveYN\"].values[0] == \"[OffN]\"):\n",
    "        final_input.append(\"[boi] \" + \"[bos] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [cls]\" + \" [eoi]\")\n",
    "        final_output.append(\"[boo] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \" [eoo]\")\n",
    "    # Otherwise, scramble up the input and output according to what is above\n",
    "    elif (training_csv.loc[[i]][\"whoTarget\"].values[0] == 0.0 and training_csv.loc[[i]][\"offensiveYN\"].values[0] == \"[OffY]\"):\n",
    "        # Case 1: given offensiveness, group, and stereotype, get post\n",
    "        final_input.append(\"[boi] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \"[ind] [eoi]\") \n",
    "        final_output.append(\"[boo] \" + \"[bos] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [cls]\" + \" [eoo]\")\n",
    "        # Case 3: given offensiveness, generate post, stereotype, and group\n",
    "        final_input.append(\"[boi] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \" [eoi]\") \n",
    "        final_output.append(\"[boo] \" + \"[bos] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [cls] \" + \"[ind] [eoo]\")\n",
    "        # Case 4: regular \n",
    "        final_input.append(\"[boi] \" + \"[bos] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [cls]\" + \" [eoi]\")\n",
    "        final_output.append(\"[boo] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \"[ind] [eoo]\")\n",
    "    else:\n",
    "        # Case 1: given offensiveness, group, and stereotype, get post\n",
    "        final_input.append(\"[boi] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \" [grp] \" + \n",
    "                          str(training_csv.loc[[i]][\"group\"].values[0]) + \" [ste] \" + \n",
    "                          str(training_csv.loc[[i]][\"implications\"].values[0]) + \" [eoi]\")\n",
    "        final_output.append(\"[boo] \" + \"[bos] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [cls]\" + \" [eoo]\")\n",
    "        # Case 2: given offensiveness and group, generate stereotype and post\n",
    "        final_input.append(\"[boi] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \" [grp] \" + \n",
    "                          str(training_csv.loc[[i]][\"group\"].values[0]) + \" [eoi]\")\n",
    "        final_output.append(\"[boo] \" + \"[bos] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [cls]\" + \" [ste] \" + \n",
    "                          str(training_csv.loc[[i]][\"implications\"].values[0]) + \" [eoo]\") \n",
    "        # Case 3: given offensiveness, generate post, stereotype, and group\n",
    "        final_input.append(\"[boi] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \" [eoi]\")\n",
    "        final_output.append(\"[boo] [bos]\" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [cls] [grp] \" + \n",
    "                          str(training_csv.loc[[i]][\"group\"].values[0]) + \" [ste] \" + \n",
    "                          str(training_csv.loc[[i]][\"implications\"].values[0]) + \" [eoo]\")         \n",
    "        # Case 4: regular\n",
    "        final_input.append(\"[boi] \" + \"[bos] \" + str(training_csv.loc[[i]][\"post\"].values[0]) + \" [cls]\" + \" [eoi]\")\n",
    "        final_output.append(\"[boo] \" + str(training_csv.loc[[i]][\"offensiveYN\"].values[0]) + \" [grp] \" + \n",
    "                          str(training_csv.loc[[i]][\"group\"].values[0]) + \" [ste] \" + \n",
    "                          str(training_csv.loc[[i]][\"implications\"].values[0]) + \" [eoo]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366898c6-605d-4102-91d9-02f185d77475",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output[0:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ae56a-9b26-4514-8c1c-eafdccd9b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scramble_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20dced-9d06-4bd6-9769-c03b31e647e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scramble_df[\"input\"] = final_input\n",
    "full_scramble_df[\"output\"] = final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcdfdb6-1c64-4d3c-a8d2-95aa6c654878",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scramble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f485c98-f009-422e-8ec1-c2bcd6418c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scramble_df.to_csv(\"full.scramble.dev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715e079-f80f-413e-b8a0-e2b1979678a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9bf5b-0fa8-4336-9546-7ec798e29c62",
   "metadata": {},
   "source": [
    "# MORE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7451f2-b294-479f-90a8-41555c44d712",
   "metadata": {},
   "source": [
    "'acl.id' is the unique ID of the entry.\n",
    "\n",
    "'Text' is the content which has been entered. All content is synthetic.\n",
    "\n",
    "'Label' is a binary variable, indicating whether or not the content has been identified as hateful. It takes two values: hate, nothate.\n",
    "\n",
    "'Type' is a categorical variable, providing a secondary label for hateful content. For hate it can take five values: Animosity, Derogation, Dehumanization, Threatening and Support for Hateful Entities. Please see the paper for more detail. For nothate the 'type' is 'none'. In round 1 the 'type' was not given and is marked as 'notgiven'.\n",
    "\n",
    "'Target' is a categorical variable, providing the group that is attacked by the hate. It can include intersectional characteristics and multiple groups can be identified. For nothate the type is 'none'. Note that in round 1 the 'target' was not given and is marked as 'notgiven'.\n",
    "\n",
    "'Level' reports whether the entry is original content or a perturbation.\n",
    "\n",
    "'Round' is a categorical variable. It gives the round of data entry (1, 2, 3 or 4) with a letter for whether the entry is original content ('a') or a perturbation ('b'). Perturbations were not made for round 1.\n",
    "\n",
    "'Round.base' is a categorical variable. It gives the round of data entry, indicated with just a number (1, 2, 3 or 4).\n",
    "\n",
    "'Split' is a categorical variable. it gives the data split that the entry has been assigned to. This can take the values 'train', 'dev' and 'test'. The choice of splits is explained in the paper.\n",
    "\n",
    "'Annotator' is a categorical variable. It gives the annotator who entered the content. Annotator IDs are random alphanumeric strings. There are 20 annotators in the dataset.\n",
    "\n",
    "'acl.id.matched' is the ID of the matched entry, connecting the original (given in 'acl.id') and the perturbed version.\n",
    "\n",
    "For identities (recorded under 'Target') we use shorthand labels to constructed the dataset, which can be converted (and grouped) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defee3f4-e43e-458b-ba7d-d5256203b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "c=pd.read_csv(\"https://raw.githubusercontent.com/bvidgen/Dynamically-Generated-Hate-Speech-Dataset/main/Dynamically%20Generated%20Hate%20Dataset%20v0.2.2.csv\", index_col=0)\n",
    "c.drop([\"acl.id\", \"X1\", \"acl.id.matched\"], axis=1)\n",
    "# get dynahate model into formal to test our model on (predict), calculate acc\n",
    "# columns for training_csv: post, implications, offy/n, whoTarget, group\n",
    "# columns to use for DynaHate : text (post), label (offy/n), target (group), (no stereotypes? See how model functions)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53175274-b0b1-43ba-b7fb-4271cc556296",
   "metadata": {},
   "source": [
    "[offY] [grp/ind] group [ste] stereotype [CLS] [bos] post [eos]\n",
    "[offY] [grp/ind] group [CLS] post [ste] stereotype [eos] \n",
    "[offY] [grp/ind] group [CLS] [ste] stereotype [bos] post [eos] \n",
    "[offY] [ste] stereotype [CLS] [bos] post [grp/ind] group [eos] \n",
    "[offY] [CLS] [bos] post [ste] stereotype [grp/ind] group [eos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a300e4d-076c-48f8-9256-3e3a8335509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# none but if its offensive\n",
    "# round 2 and above only \n",
    "c = c[(c[\"round\"] != \"1\")]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a9810-ad6b-4898-b0e5-18392f1a27f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"label\"] = c[\"label\"].apply(lambda label: 1 if label==\"nothate\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61ba2c-7c41-47f9-82ce-bc62d5750eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c[c['target'].map(c['target'].value_counts()) >= 200].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4e5e0-8fb8-4996-90c7-91e8ed6dbd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up groupings to be what model is used to from SBIC\n",
    "c[\"target\"] = c[\"target\"].map({\"notgiven\" : \"notgiven\", \"wom\":\"women\", \"bla\":\"black\", \"jew\":\"jewish\", \"mus\":\"muslim\", \"immig\":\"immigrants\", \"asi.south\":\"south asians\", \"none\" : \"none\", \"transgender\" : \"transgender people\", \"ref\":\"refugee\", \"arab\":\"arabic people\", \"indig\" : \"indigenous\", \"mixed.race\" : \"mixed people\", \"asi\" : \"asian\", \"african\" : \"african\", \"hispanic\":\"hispanic people\", \"mus.wom\" : \"muslim women\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10750ef2-1d01-44f3-bd40-48b49d122f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"target\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6d5a9-02e0-4780-ad64-397f93851e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to use for DynaHate : text (post), label (offy/n), target (group), (no stereotypes? See how model functions)\n",
    "#[\"post\", \"group\", \"implications\", \"whoTarget\", \"offensiveYN\"]\n",
    "c.drop([\"index\", \"acl.id\", \"X1\", \"round\", \"acl.id.matched\", \"annotator\", \"level\"], axis=1, index=None, inplace=True)\n",
    "c.columns=[\"post\", \"offensiveYN\", \"type\", \"group\", \"round.base\", \"split\"]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bf6ed-2407-451e-b23d-dac624bdbd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into dev, test, and train\n",
    "dev_dyna, test_dyna, train_dyna = [y for x, y in c.groupby('split', as_index=False)]\n",
    "dev_dyna.drop([\"split\"], axis=1, inplace=True)\n",
    "test_dyna.drop([\"split\"], axis=1, inplace=True)\n",
    "train_dyna.drop([\"split\"], axis=1, inplace=True)\n",
    "# QUESTION: What rows are necessary, and how are they translatable to SBIC?\n",
    "# if it's too complicated, you can take only the stage3 posts and see how our model does on the posts that we know have implications? \n",
    "# And we can measure the offensiveness classification (ie. stage 1) separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb682ef-89e5-4819-bc61-4f122827b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "all_data = all_data.append(train_dyna)[train_dyna.columns.tolist()]\n",
    "all_data = all_data.append(training_csv).dropna(axis=1, how=\"all\")\n",
    "all_data[\"whoTarget\"] = [1.0] * len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6d437-1d4f-48f7-b991-52de15b2c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"implications\"] = all_data[\"implications\"].fillna(\"[]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2378fac-a3a7-4621-b165-c6c14135b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to use for DynaHate : text (post), label (offy/n), target (group), (no stereotypes? See how model functions)\n",
    "#[\"post\", \"group\", \"implications\", \"whoTarget\", \"offensiveYN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27f711-e760-4e5b-864b-207a9e86ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge each file\n",
    "from functools import reduce\n",
    "df1 = pd.read_csv(\"implicit-hate-corpus/implicit_hate_v1_stg1.tsv\", sep='\\t')\n",
    "df2 = pd.read_csv(\"implicit-hate-corpus/implicit_hate_v1_SAP_posts.tsv\", sep=\"\\t\")\n",
    "df3 = pd.read_csv(\"implicit-hate-corpus/implicit_hate_v1_stg2.tsv\", sep=\"\\t\")\n",
    "df4 = pd.read_csv(\"implicit-hate-corpus/implicit_hate_v1_stg3.tsv\", sep=\"\\t\")\n",
    "df5 = pd.read_csv(\"implicit-hate-corpus/implicit_hate_v1_stg2_posts.tsv\", sep=\"\\t\")\n",
    "df6 = pd.read_csv(\"implicit-hate-corpus/implicit_hate_v1_stg3_posts.tsv\", sep=\"\\t\")\n",
    "df7 = pd.read_csv(\"implicit-hate-corpus/implicit_hate_v1_stg1_posts.tsv\", sep=\"\\t\")\n",
    "\n",
    "# combine each stage together\n",
    "stg1_df = df1.merge(df7[\"post\"], left_index=True, right_index=True)\n",
    "#stg2_df = df3.merge(df5[\"post\"], left_index=True, right_index=True)\n",
    "stg3_df = df4.merge(df6[\"post\"], left_index=True, right_index=True)\n",
    "total_df = pd.concat([stg1_df, stg2_df, stg3_df], ignore_index=True)\n",
    "total_df\n",
    "#data_frames = [df1, df2, df3, df4, df5, df6, df7]\n",
    "#df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['ID'],\n",
    "#                                            how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb691b-fafb-4847-b1d8-0b839b2cbe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stg1_df.drop([\"ID\", \"class\"], axis=1, inplace=True)\n",
    "stg1_df[\"offensiveYN\"] = [\"[OffN]\"] * len(stg1_df)\n",
    "stg1_df[\"whoTarget\"] = [1.0] * len(stg1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4bd3f-69b7-4306-b623-773feec61e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add offn from stage one to balance out \n",
    "# deduplicate non offensive posts (compared to SBIC) \n",
    "stg3_df.drop([\"ID\"], axis=1, inplace=True)\n",
    "stg3_df.columns = [\"group\", \"implications\", \"post\"]\n",
    "stg3_df[\"offensiveYN\"] = [\"[OffY]\"] * len(stg3_df)\n",
    "stg3_df[\"whoTarget\"] = [1.0] * len(stg3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0c76b-0da0-464a-9558-74b637990369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stg3_df = stg3_df.append(stg1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff1825-2cab-4a96-b77d-7f4fe295dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.append(stg3_df).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c0ed2-29e3-4c7e-98c0-05fd6fbb5983",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Accuracy : Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4fcdc-7951-4aa4-86d0-629a56507ac9",
   "metadata": {},
   "source": [
    "- accuracy of structure (are the tokens in the right order/right place? Good first indicator for models to see if at least the structure is learned correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914a623-e9af-4537-8ddd-a7321023915e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### for scramble model/regular model\n",
    "- traverse strings - if next token is not is expected:\n",
    "    - check if it is an incorrect prediction in the first place (those will not count)\n",
    "    - if it is not an incorrect prediction, check the count on each token. (we can start with a simple true/false, but: structure is more than just if its in the right order and place, it's about if it makes sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8fe272-2edc-44b2-a39e-cf1015f389d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for script, make this neat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b9062-8307-419b-b26d-ecd07c79ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "preds = pd.read_csv(\"predictions_2_1000.csv\", index_col=0)\n",
    "preds.columns = [\"input\", \"generated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcce45a-341b-4c1d-9c9f-bc3c6369018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val = pd.read_csv(\"SBIC.dev.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a86c97-a9d1-4f75-8d4a-96baa3aee131",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = real_val.merge(preds, on=\"input\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ccfe51-e522-4c66-8eef-eba8396dd411",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_data_preds = []\n",
    "list_of_data_real = []\n",
    "merged_df[\"output\"] = merged_df[\"output\"].apply(lambda x: x.replace(\"[boi] \", \"\")).apply(\n",
    "    lambda x: x.replace(\" [eoi]\", \"\"))\n",
    "\n",
    "merged_df[\"generated\"] = merged_df[\"generated\"].apply(lambda x: x.replace(\"<pad> \", \"\")).apply(\n",
    "    lambda x: x.replace(\" <pad>\", \"\"))\n",
    "\n",
    "y_data_real = merged_df[\"output\"].values\n",
    "y_data_preds = merged_df[\"generated\"].values\n",
    "\n",
    "# filter out incorrect results\n",
    "for i in range(0, len(merged_df)):\n",
    "    list_of_data_preds.append(list(filter(lambda x: x != \"\", [sentence.strip() for sentence in\n",
    "                                                y_data_preds[i].replace(\"<pad>\", '').replace(\"[\", '').replace(\"boo\",'')\n",
    "                                                .replace(\"grp\", '').replace(\"ste\", '').replace(\"eoo\", '')\n",
    "                                                .split(']')])))\n",
    "    list_of_data_real.append(list(filter(lambda x: x != \"\", [sentence.strip() for sentence in\n",
    "                                                y_data_real[i].replace(\"<pad>\", '').replace(\"[\", '').replace(\"boo\",'')\n",
    "                                                .replace(\"grp\", '').replace(\"ste\", '').replace(\"eoo\", '')\n",
    "                                                .split(']')])))\n",
    "\n",
    "list_of_data_real = pd.DataFrame(list_of_data_real)\n",
    "list_of_data_preds = pd.DataFrame(list_of_data_preds)\n",
    "list_of_data_real[0] = list_of_data_real[0].apply(lambda label: 1 if label == \"OffN\" else 0)\n",
    "list_of_data_preds[0] = list_of_data_preds[0].apply(lambda label: 1 if label == \"OffN\" else 0)\n",
    "mask = (list_of_data_real[0] == list_of_data_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc0e49e-9987-418e-bb56-afe684781c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "preds = pd.read_csv(\"predictions_3_pt3.csv\", index_col=0)\n",
    "preds.columns = [\"input\", \"generated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed245b8-e8e9-478c-9c4d-1d9d4707bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220ea8a-abe9-4ee4-8309-da90b1293a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3df30-7714-4358-85f8-4fe8e403eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val = pd.read_csv(\"SBIC.dev.scramble.3.5050.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ed90f-4c17-44fd-8d13-64a6eb3d34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df = real_val.merge(preds, on=\"input\", how=\"inner\")\n",
    "merged_df = real_val.merge(preds.drop_duplicates(subset=['input']), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e39fc-7333-470a-b8de-34817bc0667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcced412-ecfa-4d77-8b0d-0981ab579146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up dataframe yourself (don't do this if structure is bad, so check structure first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de183d-a776-4308-aa03-70b994be4b2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_of_data_preds = []\n",
    "list_of_data_real = []\n",
    "merged_df[\"output\"] = merged_df[\"output\"].apply(lambda x: x.replace(\"[boi] \", \"\")).apply(\n",
    "    lambda x: x.replace(\" [eoi]\", \"\"))\n",
    "\n",
    "merged_df[\"generated\"] = merged_df[\"generated\"].apply(lambda x: x.replace(\"<pad> \", \"\")).apply(\n",
    "    lambda x: x.replace(\" <pad>\", \"\"))\n",
    "\n",
    "y_data_real = merged_df[\"output\"].values\n",
    "y_data_preds = merged_df[\"generated\"].values\n",
    "\n",
    "# filter out incorrect results\n",
    "for i in range(0, len(merged_df)):\n",
    "    list_of_data_preds.append(list(filter(lambda x: x != \"\", [sentence.strip() for sentence in\n",
    "                                                y_data_preds[i].replace(\"<pad>\", '').replace(\"[\", '').replace(\"boo\",'')\n",
    "                                                .replace(\"grp\", '').replace(\"ste\", '').replace(\"eoo\", '')\n",
    "                                                .split(']')])))\n",
    "    list_of_data_real.append(list(filter(lambda x: x != \"\", [sentence.strip() for sentence in\n",
    "                                                y_data_real[i].replace(\"<pad>\", '').replace(\"[\", '').replace(\"boo\",'')\n",
    "                                                .replace(\"grp\", '').replace(\"ste\", '').replace(\"eoo\", '')\n",
    "                                                .split(']')])))\n",
    "\n",
    "list_of_data_real = pd.DataFrame(list_of_data_real)\n",
    "list_of_data_preds = pd.DataFrame(list_of_data_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a536ca-a90f-4834-8d58-6bc58f02a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_data_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c887d545-fce1-424b-a9f0-c9a468263b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_data_real[0] = list_of_data_real[0].apply(lambda label: 1 if label == \"OffN\" else 0)\n",
    "list_of_data_preds[0] = list_of_data_preds[0].apply(lambda label: 1 if label == \"OffN\" else 0)\n",
    "mask = (list_of_data_real[0] == list_of_data_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60edd4-b1af-4adf-ad20-17304027d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "merged_df_preds = merged_df[np.array(mask,dtype=bool)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83841e-c39a-43f2-bc84-56b96de595a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1eaa83-1c24-4774-bf3b-642f8f4e111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_regular = merged_df[np.array(mask,dtype=bool)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e731150-1441-4ee9-b4f9-9fcf10860b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71965a45-e4da-4cc7-afe1-d41c9310af02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "total_values = []\n",
    "# TODO: add in a check to make sure the prediction is correct before adding it to total_values\n",
    "for i in range(0, len(merged_df_preds)):\n",
    "    # find all tokens between square brackets\n",
    "    tokens_input = re.findall(\"(?<=\\[)[^]]+(?=\\])\", merged_df_preds[\"output\"].tolist()[i])\n",
    "    tokens_generated = re.findall(\"(?<=\\[)[^]]+(?=\\])\", merged_df_preds[\"generated\"].tolist()[i])\n",
    "    #compare the arrays elementwise to determine number of tokens correctly preserved, divide by total amount of tokens preserved\n",
    "    try:\n",
    "        total_values.append((np.array(tokens_input)==np.array(tokens_generated)).sum()/len(tokens_input))\n",
    "    #short term solution to deal with arrays that are not the same length: talk in meeting about best way to mitigate\n",
    "    except:\n",
    "        total_values.append(0);\n",
    "print(np.mean(total_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0573ac24-95a3-41e3-954e-2ed1bba807e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[boo', ' this is an example [boi', ' that would be [eoo']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(\"(?!<=\\[)[^]]+(?=\\])\", \"[boo] this is an example [boi] that would be [eoo] useful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6b86c-fc44-4e30-9990-754aebcbe04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\|(?![^\\[]*\\])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52759163-bf69-4f95-9b4f-bcaa2b2d6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_structure = np.mean(total_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efe867-7ab5-4464-942d-030e8acea32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val[\"input\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37249d3a-8168-4ea1-991d-06f6c03534d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8de22b6a-a082-48f4-8159-9274cd33eb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'Source Text': '[boi] There are too many costas in this country [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> linguri<pad> <pad> (<pad> <pad> -<pad> <pad> m<pad> <pad> reteta<pad> <pad> în<pad> <pad> –<pad> <pad> Ach<pad> <pad> zu<pad> <pad>,<pad> <pad> î<pad> <pad> ü<pad> <pad> :<pad> <pad> a<pad> <pad> s<pad> <pad> beauftragte<pad> <pad> ende<pad> <pad> An<pad> <pad> ă<pad> <pad> Diese'},\n",
       " 1: {'Source Text': '[boi] There is way too many m0ng0l0id kids at my school,  they should be sent to the special school [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> beauftragte<pad> <pad> Stiftung<pad> <pad> zu<pad> <pad> ü<pad> <pad> în<pad> <pad> organiza<pad> <pad> veți<pad> <pad> București<pad> <pad> î<pad> <pad> -<pad> <pad> zuführen<pad> <pad> a<pad> <pad> placut<pad> <pad> linguri<pad> <pad> ă<pad> <pad> Brașov<pad> <pad> ș<pad> <pad> instituții<pad> <pad> schule<pad> <pad> Gemeinde'},\n",
       " 2: {'Source Text': '[boi] I called my brother a twat and my mom got so mad at me. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> în<pad> <pad> <pad> <pad> placut<pad> <pad> gasest<pad> <pad> „<pad> <pad> linguri<pad> <pad> („<pad> <pad> între<pad> <pad> Între<pad> <pad> organiza<pad> <pad> ingrijire<pad> <pad> sunteti<pad> <pad> în<pad> <pad>,<pad> <pad> aflat<pad> <pad> -<pad> <pad> î<pad> <pad> zu<pad> <pad> înțeleg<pad> <pad> a<pad> <pad> țele'},\n",
       " 3: {'Source Text': '[boi] the worst of them are the taaaaaaaaaards because they are a massive burden on all of us. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> gasest<pad> <pad> în<pad> <pad> <pad> <pad> placut<pad> <pad> „<pad> <pad> sunteti<pad> <pad> Constanța<pad> <pad> descarc<pad> <pad> Ihre<pad> <pad> linguri<pad> <pad> („<pad> <pad> București<pad> <pad> înțeleg<pad> <pad> veți<pad> <pad> În<pad> <pad> Între<pad> <pad> -<pad> <pad> La<pad> <pad> Multumesc<pad> <pad> Und<pad> <pad>,'},\n",
       " 4: {'Source Text': '[boi] the worst of them are the viruses because they are a massive burden on all of us. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> în<pad> <pad> <pad> <pad> „<pad> <pad> Constanța<pad> <pad> înțeleg<pad> <pad> („<pad> <pad> sunteti<pad> <pad> București<pad> <pad> veți<pad> <pad> Între<pad> <pad> între<pad> <pad> În<pad> <pad> aflat<pad> <pad> descarc<pad> <pad> placut<pad> <pad> învăța<pad> <pad> :<pad> <pad> și<pad> <pad>,<pad> <pad> susține<pad> <pad> gasest'},\n",
       " 5: {'Source Text': '[boi] it is not niiiice to be around reeetaaaardss [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> gasest<pad> <pad> placut<pad> <pad> linguri<pad> <pad> în<pad> <pad> suprafata<pad> <pad> sunteti<pad> <pad> (<pad> <pad> -<pad> <pad> î<pad> <pad> a<pad> <pad> București<pad> <pad> organiza<pad> <pad> să<pad> <pad> zu<pad> <pad> („<pad> <pad> „<pad> <pad> s<pad> <pad> de<pad> <pad> au<pad> <pad> manifest'},\n",
       " 6: {'Source Text': '[boi] it is not nice at all to be around republicans [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> (<pad> <pad> app<pad> <pad> ou<pad> <pad> par<pad> <pad> [<pad> <pad> s<pad> <pad> -<pad> <pad> —<pad> <pad> or<pad> <pad> inter<pad> <pad> entre<pad> <pad> oder<pad> <pad> de<pad> <pad> emp<pad> <pad> about<pad> <pad> administration<pad> <pad> prom<pad> <pad> mari<pad> <pad> près<pad> <pad> ressort'},\n",
       " 7: {'Source Text': '[boi] travellers have a certain aroma [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> Un a apologie a<pad> <pad> „<pad> <pad> Ihre aa<pad> auna<pad> „Augenda et aufgrund der <unk> ußerungen<pad> <pad> Anmerkungen<pad> Darüber hinaus bietet es a'},\n",
       " 8: {'Source Text': '[boi] you have a certain aroma [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> „<pad> <pad> Sie a a certain aroma a<pad> <pad> oder aa<pad> auna<pad> „Überhaupt<pad> <pad> Anscheinende<pad> <pad> Ihre<pad> <pad> Aufklärung<pad> <pad> Zuletzt aufgrund der<pad> <pad> Unmittelbar apropos'},\n",
       " 9: {'Source Text': \"[boi] Can you smell these dirty muzzies? It's a brutal stank [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> Între Între<pad> <pad> <pad> <pad> Un<pad> <pad> În<pad> <pad> Autor<pad> <pad> An<pad> <pad> Măs<pad> <pad> La<pad> <pad> „<pad> <pad> Într-un<pad> <pad> în<pad> <pad> Situ<pad> <pad> A<pad> <pad> Ob<pad> <pad> Folosi Folosi Folosi<pad> <pad> Acest<pad> <pad> Câ<pad> <pad> Au<pad> <pad> Sunt'},\n",
       " 10: {'Source Text': \"[boi] Can you smell these dirty saucepans? It's a brutal stank [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> Între Între Între stank<pad> <pad> Autor<pad> <pad> An<pad> <pad> Un<pad> <pad> În<pad> <pad> „<pad> <pad> în<pad> <pad> La<pad> <pad> A<pad> <pad> Eine<pad> <pad> Une<pad> <pad> Au<pad> <pad>,<pad> <pad> Câ<pad> <pad> Este a stanc<pad> <pad> Măs<pad>'},\n",
       " 11: {'Source Text': '[boi] I have been called a dirty, stinky and lazy all because i am black [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> î<pad> <pad> placut<pad> <pad> linguri<pad> <pad> gasest<pad> <pad> în<pad> <pad> sunteti<pad> <pad> -<pad> <pad> prim<pad> <pad> enquête<pad> <pad> @<pad> <pad> s<pad> <pad>?<pad> <pad> »,<pad> <pad> «<pad> <pad> »<pad> <pad> ediție<pad> <pad> informatiile<pad> <pad> (<pad> <pad> elle<pad> <pad> —'},\n",
       " 12: {'Source Text': \"[boi] Black people are all dirty, stinky and lazy. You won't change my mind [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> în<pad> <pad> <pad> <pad> Între<pad> <pad> între<pad> <pad> organiza<pad> <pad> „<pad> <pad> placut<pad> <pad>?<pad> <pad> București<pad> <pad> veți<pad> <pad> Brașov<pad> <pad> sunteti<pad> <pad> înțeleg<pad> <pad> gasest<pad> <pad> În<pad> <pad> Situ<pad> <pad> cunoaște<pad> <pad> Europa<pad> <pad> Un<pad> <pad> ați<pad> <pad> învăța'},\n",
       " 13: {'Source Text': '[boi] Trans are sycophantic [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> în<pad> <pad> (<pad> <pad> î<pad> <pad> placut<pad> <pad> împlin<pad> <pad> gasest<pad> <pad> Constanța<pad> <pad> -<pad> <pad> Între<pad> <pad> București<pad> <pad> Serbia<pad> <pad> ingrijire<pad> <pad> sunteti<pad> <pad> Crăciun<pad> <pad> An<pad> <pad> Autor<pad> <pad> În<pad> <pad> între<pad> <pad> Ac<pad> <pad> de'},\n",
       " 14: {'Source Text': '[boi] Trans are so brave [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> Trans Trans Trans trans trans trans Trans Trans  trans trans  trans Trans trans Trans  Trans Transtrans trans transtrans trans Transtrans Trans TransTrans Trans Trans Pré trans trans Pré Pré Pré  trans  Trans trans   transtrans Trans transtranstrans trans trans transtrans  trans Pré  Trans'},\n",
       " 15: {'Source Text': '[boi] Indigenous are so hospitable [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> placut<pad> <pad> în<pad> <pad> gasest<pad> <pad> linguri<pad> <pad> ingrijire<pad> <pad> sunteti<pad> <pad> î<pad> <pad> Constanța<pad> <pad> a<pad> <pad> București<pad> <pad> între<pad> <pad> –<pad> <pad> (<pad> <pad> s<pad> <pad> -<pad> <pad> în<pad> <pad> —<pad> <pad> suprafata<pad> <pad> Între<pad> <pad> ü'},\n",
       " 16: {'Source Text': '[boi] yeah life is cunty but fucking hell get over it [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> linguri<pad> <pad> împlin<pad> <pad> gasest<pad> <pad> în<pad> <pad> î<pad> <pad> a<pad> <pad> (<pad> <pad> )<pad> <pad> -<pad> <pad> s<pad> <pad> sunteti<pad> <pad> :<pad> <pad> —<pad> <pad> au<pad> <pad> ü<pad> <pad> autorité<pad> <pad> („<pad> <pad> ]<pad> <pad> (<pad> <pad> 8)'},\n",
       " 17: {'Source Text': '[boi] yeah life is cunty but fucking hell get over it you pussy [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> î<pad> <pad> în<pad> <pad> veți<pad> <pad> veţi<pad> <pad> împlin<pad> <pad> –<pad> <pad> -<pad> <pad> Între<pad> <pad> —<pad> <pad> s<pad> <pad> Ihre<pad> <pad> Parlament<pad> <pad> a<pad> <pad> („<pad> <pad> â<pad> <pad> Î<pad> <pad> ü<pad> <pad> ări<pad> <pad> sunteti<pad> <pad> ('},\n",
       " 18: {'Source Text': '[boi] There are absolutely loads of filthy muslims on my street [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> auf<pad> <pad> -<pad> <pad> s<pad> <pad> în<pad> <pad> mettez<pad> <pad> de<pad> <pad> adresse<pad> <pad> –<pad> <pad> enquête<pad> <pad> près<pad> <pad> dé<pad> <pad> a<pad> <pad> met<pad> <pad> en<pad> <pad> la<pad> <pad> ü<pad> <pad> Wohnung<pad> <pad> aflat<pad> <pad> (<pad> <pad> unter'},\n",
       " 19: {'Source Text': '[boi] There are loads of black people on my street, makes me feel unconfortable [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> -<pad> <pad> placut<pad> <pad> linguri<pad> <pad> (<pad> <pad> în<pad> <pad> a<pad> <pad> între<pad> <pad> –<pad> <pad> î<pad> <pad> s<pad> <pad> mili<pad> <pad> ü<pad> <pad> suprafata<pad> <pad> en<pad> <pad> Brașov<pad> <pad> sunteti<pad> <pad> organiza<pad> <pad> „<pad> <pad> demonstr<pad> <pad> manifest'},\n",
       " 20: {'Source Text': '[boi] There are so many gangs on my street, I need  to move out ASAP. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> gasest<pad> <pad> Între<pad> <pad> „<pad> <pad> <pad> <pad> București<pad> <pad> Brașov<pad> <pad> („<pad> <pad> în<pad> <pad> între<pad> <pad> organiza<pad> <pad> Asociaţi<pad> <pad> Wohnung<pad> <pad> placut<pad> <pad> Parlament<pad> <pad> Regulament<pad> <pad> Ansprechpartner<pad> <pad> Mă<pad> <pad> În<pad> <pad> Agenda<pad> <pad> Förder<pad> <pad> Bürgermeister'},\n",
       " 21: {'Source Text': \"[boi] that’s the things with the mongs. They're just like monkeys with their lack of knowledge [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> placut<pad> <pad> în<pad> <pad> „<pad> <pad> <pad> <pad> organiza<pad> <pad>,<pad> <pad> între<pad> <pad> să<pad> <pad> zu<pad> <pad> -<pad> <pad> sunteti<pad> <pad> \"<pad> <pad> ü<pad> <pad> persoane<pad> <pad> cu<pad> <pad> :<pad> <pad> de<pad> <pad> î<pad> <pad> «<pad> <pad>?<pad> <pad> („'},\n",
       " 22: {'Source Text': \"[boi] that’s the things with the apes. They're just like monkeys with their lack of knowledge [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> „<pad> <pad> în<pad> <pad>,<pad> <pad> «<pad> <pad> \"<pad> <pad> placut placut placut<pad> <pad> Însă<pad> <pad> Sunt apes<pad> <pad> An<pad> <pad> Au<pad> <pad> Apes,<pad> apologie<pad> <pad> Un<pad> <pad> La<pad> <pad> In<pad> <pad>'},\n",
       " 23: {'Source Text': '[boi] I think mongs are more similar to apes than humans. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> în<pad> <pad> „<pad> <pad> placut<pad> <pad> <pad> <pad> linguri<pad> <pad> Între<pad> <pad> organiza<pad> <pad> Asociaţi<pad> <pad> sunteti<pad> <pad> („<pad> <pad> Constanța<pad> <pad> București<pad> <pad> înțeleg<pad> <pad> gasest<pad> <pad> descarc<pad> <pad> Brașov<pad> <pad> Folosi<pad> <pad> învăța<pad> <pad> În<pad> <pad> susține<pad> <pad> Verständnis'},\n",
       " 24: {'Source Text': '[boi] I think mandrills are more similar to apes than humans. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> în<pad> <pad> „<pad> <pad> <pad> <pad> linguri<pad> <pad> Între<pad> <pad> sunteti<pad> <pad> Folosi<pad> <pad> placut<pad> <pad> gasest<pad> <pad> descarc<pad> <pad> București<pad> <pad> înțeleg<pad> <pad> învăța<pad> <pad> Constanța<pad> <pad> („<pad> <pad> organiza<pad> <pad> Brașov<pad> <pad> Regulament<pad> <pad> În<pad> <pad> împlin<pad> <pad> între'},\n",
       " 25: {'Source Text': '[boi] Where are there no halal shops here despite the high concentration of muslim households? [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> gasest<pad> <pad> placut<pad> <pad> <pad> <pad> în<pad> <pad> linguri<pad> <pad> sunteti<pad> <pad> „<pad> <pad> Constanța<pad> <pad> :<pad> <pad> «<pad> <pad> -<pad> <pad> între<pad> <pad> Între<pad> <pad> București<pad> <pad> Wohnung<pad> <pad> Wohn<pad> <pad> („<pad> <pad>?<pad> <pad> oder<pad> <pad> (<pad> <pad> rät'},\n",
       " 26: {'Source Text': '[boi] Why is there such a high concentration of muslims here compared to normal people? [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> gasest<pad> <pad> placut<pad> <pad> Între<pad> <pad> „<pad> <pad> <pad> <pad> linguri<pad> <pad> Constanța<pad> <pad> sunteti<pad> <pad> Unter<pad> <pad> („<pad> <pad> Parlament<pad> <pad> Ob<pad> <pad> Erdogan<pad> <pad> în<pad> <pad> București<pad> <pad> Landes<pad> <pad> AFP<pad> <pad> Să<pad> <pad> descarc<pad> <pad> Beschreibung<pad> <pad> Welche'},\n",
       " 27: {'Source Text': '[boi] yo, those beetles seem like cockroaches to me with their infestation. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> „<pad> <pad> în<pad> <pad> <pad> <pad> („<pad> <pad> sunteti<pad> <pad> între<pad> <pad> înțeleg<pad> <pad> gasest<pad> <pad> împlin<pad> <pad>,<pad> <pad> veți<pad> <pad> București<pad> <pad> și<pad> <pad> –<pad> <pad> ții<pad> <pad> zu<pad> <pad> î<pad> <pad> în<pad> <pad> ă<pad> <pad> Mă<pad> <pad> să'},\n",
       " 28: {'Source Text': \"[boi] My street is riddled with cats who've probably migrated from the ghost town nearby [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> sunteti<pad> <pad> <pad> <pad> linguri<pad> <pad> placut<pad> <pad> Între<pad> <pad> în<pad> <pad> î<pad> <pad> Welche<pad> <pad>?<pad> <pad> An<pad> <pad> Mai<pad> <pad> În<pad> <pad> Autor<pad> <pad> Asociaţi<pad> <pad> Î<pad> <pad> ulevard<pad> <pad> „<pad> <pad> –<pad> <pad> Unter<pad> <pad> București<pad> <pad> Constanța'},\n",
       " 29: {'Source Text': \"[boi] My street is riddled with plebs who've probably migrated from the ghost town nearby [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> sunteti<pad> <pad> placut<pad> <pad> linguri<pad> <pad> <pad> <pad> în<pad> <pad> ulevard<pad> <pad> „<pad> <pad> –<pad> <pad> Berlin<pad> <pad> München<pad> <pad> București<pad> <pad> Constanța<pad> <pad> Între<pad> <pad> Welche<pad> <pad> An<pad> <pad> Mai<pad> <pad> Exista<pad> <pad> Brașov<pad> <pad> (<pad> <pad> î<pad> <pad>?'},\n",
       " 30: {'Source Text': '[boi] the black women on my street have been heavily mistreated by our neighbours. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> în<pad> <pad> Constanța<pad> <pad> <pad> <pad> București<pad> <pad> Între<pad> <pad> organiza<pad> <pad> „<pad> <pad> sunteti<pad> <pad> În<pad> <pad> descarc<pad> <pad> înțeleg<pad> <pad> între<pad> <pad> Parlament<pad> <pad> Mă<pad> <pad> placut<pad> <pad> Regulament<pad> <pad> Situ<pad> <pad>,<pad> <pad> «<pad> <pad> Brașov<pad> <pad> („'},\n",
       " 31: {'Source Text': \"[boi] The road on my street doesn't have a ramp or braille to cater for the disabled or blind, gOOD!! [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> în<pad> <pad> Mă<pad> <pad> Între<pad> <pad> Oblig<pad> <pad> În<pad> <pad> „<pad> <pad> Câ<pad> <pad> Îm<pad> <pad> Autor<pad> <pad> Parlament<pad> <pad> Am<pad> <pad> Folosi<pad> <pad> Pentru<pad> <pad> Und<pad> <pad> Egal<pad> <pad> Welche<pad> <pad> Im<pad> <pad> Unabhängig von<pad> <pad> La'},\n",
       " 32: {'Source Text': '[boi] There are so many Polish people living on the streets [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> sunteti<pad> <pad> <pad> <pad> placut<pad> <pad> linguri<pad> <pad> „<pad> <pad> klär<pad> <pad> –<pad> <pad> Wohn<pad> <pad> ü<pad> <pad> Wohnung<pad> <pad> asse<pad> <pad> -<pad> <pad> s<pad> <pad> ende<pad> <pad> —<pad> <pad> :<pad> <pad> «<pad> <pad> suprafata<pad> <pad> versammlung<pad> <pad> <unk> <pad> <pad> Brașov'},\n",
       " 33: {'Source Text': \"[boi] The smell of jews is digusting, it's like a pile of snot, if you know what I mean [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> gasest<pad> <pad> în<pad> <pad> <pad> <pad> placut<pad> <pad> „<pad> <pad>?<pad> <pad>,<pad> <pad> aplicatii<pad> <pad> între<pad> <pad> împlin<pad> <pad> sunteti<pad> <pad> Ihre<pad> <pad> de<pad> <pad> î<pad> <pad> -<pad> <pad> oder<pad> <pad> der<pad> <pad> zu<pad> <pad> öffentlich<pad> <pad> «<pad> <pad> »,'},\n",
       " 34: {'Source Text': \"[boi] The smell of fish is digusting, it's like a pile of snot, if you know what I mean [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> gasest gasest gasest<pad> <pad> în<pad> <pad> placut<pad> <pad> „<pad> <pad> î<pad> <pad> Ihre<pad> <pad> împlin<pad> <pad>?<pad> <pad>,<pad> <pad> de<pad> <pad> între<pad> <pad> Între<pad> <pad> în<pad> <pad> sunteti<pad> <pad> aplicatii<pad> <pad> suprafata<pad> <pad> veți<pad> <pad> înțeleg<pad> <pad> București<pad>'},\n",
       " 35: {'Source Text': '[boi] moooongoooos are like puppies, really nice but you get tired of them after some time. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> în<pad> <pad> „<pad> <pad> („<pad> <pad> gasest<pad> <pad> înțeleg<pad> <pad> între<pad> <pad> Între<pad> <pad> București<pad> <pad> Constanța<pad> <pad> împlin<pad> <pad> placut<pad> <pad> susține<pad> <pad> instituții<pad> <pad> învăța<pad> <pad> și<pad> <pad> susțin<pad> <pad> organiza<pad> <pad> ediție<pad> <pad> părți<pad> <pad> veți'},\n",
       " 36: {'Source Text': '[boi] my parents are like puppies, really kind but you get tired of them after a while [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> în<pad> <pad> În<pad> <pad> „<pad> <pad> Autor<pad> <pad> Ob<pad> <pad> Un<pad> <pad> Und<pad> <pad> Folosi<pad> <pad> Mă<pad> <pad> Îm<pad> <pad> Sunt<pad> <pad> An<pad> <pad> Între<pad> <pad> Crăciun<pad> <pad> A<pad> <pad> Am<pad> <pad> Ad<pad> <pad> De<pad> <pad> Probabil<pad> <pad> Vor'},\n",
       " 37: {'Source Text': '[boi] ew that cripple stunk so bad [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> -<pad> <pad> s<pad> <pad> —<pad> <pad> a<pad> <pad> –<pad> <pad> e<pad> <pad> î<pad> <pad> ü<pad> <pad> gasest<pad> <pad> sunteti<pad> <pad> en<pad> <pad> zu<pad> <pad>?<pad> <pad> :<pad> <pad>,<pad> <pad> <unk> <pad> <pad> )<pad> <pad> (<pad> <pad> ),<pad> <pad> („'},\n",
       " 38: {'Source Text': '[boi] ew that girl stunk so bad [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> —<pad> <pad> („<pad> <pad> )<pad> <pad>?<pad> <pad> (<pad> <pad> ]<pad> <pad> [<pad> <pad> ),<pad> <pad> (<pad> <pad> -<pad> <pad> s<pad> <pad> ü<pad> <pad> placut<pad> <pad> sunteti<pad> <pad> în<pad> <pad> a<pad> <pad> –<pad> <pad> <unk> <pad> <pad> î<pad> <pad> :'},\n",
       " 39: {'Source Text': '[boi] idk about you but I believe jews are controlling us [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> sunteti<pad> <pad> placut<pad> <pad> gasest<pad> <pad> -<pad> <pad> <pad> <pad> I<pad> <pad> i<pad> <pad> în<pad> <pad> între<pad> <pad>?<pad> <pad> veți<pad> <pad> »,<pad> <pad> –<pad> <pad> —<pad> <pad> [...]<pad> <pad>...<pad> <pad> [<pad> <pad> veţi<pad> <pad> î<pad> <pad> vous<pad> <pad> a'},\n",
       " 40: {'Source Text': '[boi] idk about you but I believe govt are controlling us [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> I<pad> <pad> s<pad> <pad> i<pad> <pad> -<pad> <pad>,<pad> <pad> în<pad> <pad> –<pad> <pad> —<pad> <pad> a<pad> <pad> placut<pad> <pad> veţi<pad> <pad> î<pad> <pad> ü<pad> <pad> d<pad> <pad> en<pad> <pad> e<pad> <pad> :<pad> <pad> ’<pad> <pad>?<pad> <pad> avez'},\n",
       " 41: {'Source Text': '[boi] come on, the muslims are real sus with their warmongering religion [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> în<pad> <pad> <pad> <pad> „<pad> <pad> linguri<pad> <pad> împlin<pad> <pad> î<pad> <pad> organiza<pad> <pad> gasest<pad> <pad> placut<pad> <pad> en<pad> <pad> conving<pad> <pad> israel<pad> <pad> –<pad> <pad> -<pad> <pad> în<pad> <pad> între<pad> <pad> clientii<pad> <pad> familia<pad> <pad> a<pad> <pad>,<pad> <pad> der'},\n",
       " 42: {'Source Text': '[boi] come on, they were real sus with their warmongering views [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> placut<pad> <pad> în<pad> <pad>,<pad> <pad> „<pad> <pad> –<pad> <pad> s<pad> <pad> (<pad> <pad> »,<pad> <pad> și<pad> <pad> București<pad> <pad> î<pad> <pad> en<pad> <pad> ’<pad> <pad> a<pad> <pad> cu<pad> <pad> -<pad> <pad> în<pad> <pad> informatiile<pad> <pad> au<pad> <pad> »'},\n",
       " 43: {'Source Text': '[boi] This area is reserved for aboriginal people only [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> (<pad> <pad> a<pad> <pad> <pad> <pad> »<pad> <pad> Diese<pad> <pad> This area is reserved for aboriginal people ab<pad> <pad> -<pad> <pad>.<pad> <pad> Ad<pad> <pad> Dies<pad> <pad> réservé réservé réservé for ab aboriginal aboriginal<pad> <pad> s<pad> <pad> Attend<pad> <pad> Interview<pad> <pad> Pré<pad> <pad>'},\n",
       " 44: {'Source Text': \"[boi] This area is reserved, it's for non aboriginal people only [eoi]\",\n",
       "  'Generated Text': '<pad> <pad> <pad> gasest<pad> <pad> placut<pad> <pad> <pad> <pad> în<pad> <pad> (<pad> <pad> („<pad> <pad> „<pad> <pad> -<pad> <pad> suprafata<pad> <pad> linguri<pad> <pad> pentru<pad> <pad> împlin<pad> <pad> —<pad> <pad> ă<pad> <pad> –<pad> <pad> descarc<pad> <pad>,<pad> <pad> organiza<pad> <pad> persoane<pad> <pad> Asociaţi<pad> <pad> a'},\n",
       " 45: {'Source Text': '[boi] muslims smell [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> (<pad> <pad> placut<pad> <pad> în<pad> <pad> München<pad> <pad> București<pad> <pad> Ahmed<pad> <pad> —<pad> <pad> -<pad> <pad>...<pad> <pad> •<pad> <pad> [<pad> <pad> «<pad> <pad> UN<pad> <pad> Sara<pad> <pad> Wohnung<pad> <pad> Berlin<pad> <pad> Ausstellung<pad> <pad> „<pad> <pad> [...]<pad> <pad> s'},\n",
       " 46: {'Source Text': '[boi] dogs smell [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad>.<pad> <pad> (<pad> <pad> —<pad> <pad>,<pad> <pad> dogs smell smell smell<pad> <pad> smell smell.<pad> —<pad>.<pad>. <pad>,<pad> s<pad> <pad> s smell smell <pad>..<pad> ——<pad>.—<pad> — <pad> —.<pad>'},\n",
       " 47: {'Source Text': '[boi] Feeebleee-miiindeeed people are really nice but you get tired of them after some time. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> „<pad> <pad> <pad> <pad> în<pad> <pad> gasest<pad> <pad> Între<pad> <pad> București<pad> <pad> Brașov<pad> <pad> Folosi<pad> <pad> înțeleg<pad> <pad> instituții<pad> <pad> În<pad> <pad> între<pad> <pad> organiza<pad> <pad> Parlament<pad> <pad> și<pad> <pad> sunteti<pad> <pad> Autor<pad> <pad> î<pad> <pad> placut<pad> <pad> -<pad> <pad> („'},\n",
       " 48: {'Source Text': '[boi] Narrow minded people are really nice but you get tired of them after some time. [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> gasest<pad> <pad> în<pad> <pad> <pad> <pad> „<pad> <pad> Între<pad> <pad> București<pad> <pad> sunteti<pad> <pad> înțeleg<pad> <pad> Brașov<pad> <pad> („<pad> <pad> Constanța<pad> <pad> organiza<pad> <pad> între<pad> <pad> și<pad> <pad> susține<pad> <pad> instituții<pad> <pad> Parlament<pad> <pad> împlin<pad> <pad> î<pad> <pad> placut<pad> <pad> ediție'},\n",
       " 49: {'Source Text': '[boi] all of those dirty dishes, bet they never wash them [eoi]',\n",
       "  'Generated Text': '<pad> <pad> <pad> <pad> <pad> în<pad> <pad> „<pad> <pad> î<pad> <pad> să<pad> <pad> -<pad> <pad>,<pad> <pad> În<pad> <pad> Să<pad> <pad> zu<pad> <pad> –<pad> <pad> Între<pad> <pad> Autor<pad> <pad> Folosi<pad> <pad> <unk> <pad> <pad> —<pad> <pad> sunteti<pad> <pad> Ihre<pad> <pad> veți<pad> <pad> instituții<pad> <pad> ș'}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.read_csv(\"predictions_test_2.csv\", index_col=0)\n",
    "predictions.transpose().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1aa683fc-248e-46f5-aa69-2009f387c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pd.read_csv(\"predictions_test.csv\", index_col=0)\n",
    "\n",
    "#for i in range(0, len(pred_test)):\n",
    "#    print(list(filter(lambda x: x != \"\", [sentence.strip() for sentence in\n",
    "#                                                pred_test[i].replace(\"<pad>\", '')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4eaad37e-62f5-4b26-b8f0-e4dfaedd3369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> <pad> <pad> <pad> <pad> linguri<pad> <pad> (<pad> <pad> -<pad> <pad> m<pad> <pad> reteta<pad> <pad> în<pad> <pad> –<pad> <pad> Ach<pad> <pad> zu<pad> <pad>,<pad> <pad> î<pad> <pad> ü<pad> <pad> :<pad> <pad> a<pad> <pad> s<pad> <pad> beauftragte<pad> <pad> ende<pad> <pad> An<pad> <pad> ă<pad> <pad> Diese',\n",
       " '<pad> <pad> <pad> <pad> <pad> beauftragte<pad> <pad> Stiftung<pad> <pad> zu<pad> <pad> ü<pad> <pad> în<pad> <pad> organiza<pad> <pad> veți<pad> <pad> București<pad> <pad> î<pad> <pad> -<pad> <pad> zuführen<pad> <pad> a<pad> <pad> placut<pad> <pad> linguri<pad> <pad> ă<pad> <pad> Brașov<pad> <pad> ș<pad> <pad> instituții<pad> <pad> schule<pad> <pad> Gemeinde',\n",
       " '<pad> <pad> <pad> în<pad> <pad> <pad> <pad> placut<pad> <pad> gasest<pad> <pad> „<pad> <pad> linguri<pad> <pad> („<pad> <pad> între<pad> <pad> Între<pad> <pad> organiza<pad> <pad> ingrijire<pad> <pad> sunteti<pad> <pad> în<pad> <pad>,<pad> <pad> aflat<pad> <pad> -<pad> <pad> î<pad> <pad> zu<pad> <pad> înțeleg<pad> <pad> a<pad> <pad> țele',\n",
       " '<pad> <pad> <pad> gasest<pad> <pad> în<pad> <pad> <pad> <pad> placut<pad> <pad> „<pad> <pad> sunteti<pad> <pad> Constanța<pad> <pad> descarc<pad> <pad> Ihre<pad> <pad> linguri<pad> <pad> („<pad> <pad> București<pad> <pad> înțeleg<pad> <pad> veți<pad> <pad> În<pad> <pad> Între<pad> <pad> -<pad> <pad> La<pad> <pad> Multumesc<pad> <pad> Und<pad> <pad>,']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[\"Generated Text\"].values.tolist()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0bc6e-dc69-4976-bc6d-6e757368b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "preds = pd.read_csv(\"predictions_2_1000.csv\", index_col=0)\n",
    "preds.columns = [\"input\", \"generated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e63c3-c4ef-4e12-ac12-65c70882af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val = pd.read_csv(\"SBIC.dev.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf9ef3-5105-438c-b8cc-a7bd6205f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = real_val.merge(preds, on=\"input\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef80d7-fc15-48bb-a2e1-10713dc34563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "total_values = []\n",
    "# TODO: add in a check to make sure the prediction is correct before adding it to total_values\n",
    "for i in range(0, len(merged_df)):\n",
    "    # find all tokens between square brackets\n",
    "    tokens_input = re.findall(\"(?<=\\[)[^]]+(?=\\])\", merged_df[\"output\"].tolist()[i])\n",
    "    tokens_generated = re.findall(\"(?<=\\[)[^]]+(?=\\])\", merged_df[\"generated\"].tolist()[i])\n",
    "    #compare the arrays elementwise to determine number of tokens correctly preserved, divide by total amount of tokens preserved\n",
    "    try:\n",
    "        total_values.append((np.array(tokens_input)==np.array(tokens_generated)).sum()/len(tokens_input))\n",
    "    #short term solution to deal with arrays that are not the same length: talk in meeting about best way to mitigate\n",
    "    except:\n",
    "        total_values.append(0);\n",
    "\n",
    "print(np.mean(total_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58aaef-0b43-4e59-bee5-a5af7cc8d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_structure = np.mean(total_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1792c-14a0-486d-a414-69c157cc68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_val[\"input\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda95383-ed06-4933-96dd-9e6055e01409",
   "metadata": {},
   "source": [
    "# Accuracy : Generation of Similar values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99107f6b-dd0d-4189-9f6a-0652b5e8f9e3",
   "metadata": {},
   "source": [
    "- frequency of generation (check how frequently the model learns a pattern, generate a heatmap of sorts with keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a9184-3cce-452d-a976-574f35d4b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(merged_df_preds[\"generated\"].tolist()))/len(set(merged_df_preds[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c588aa6-ff30-49f9-9975-2b6b2a52f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.util import ngrams\n",
    " \n",
    "# Function to generate n-grams from sentences.\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d2bf8-043e-42ee-bac5-904773bb0ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_vs_act = []\n",
    "gen_vs_gen = []\n",
    "for i in range(0, len(merged_df_preds)):\n",
    "    generated = merged_df_preds[\"generated\"].tolist()[i].replace(\"<pad>\", \"\").replace(\"[eoo]\", \"\").replace(\"[cls]\", \"\").replace(\"[boo]\",\"\")\n",
    "    output = merged_df_preds[\"output\"].tolist()[i].replace(\"<pad>\", \"\").replace(\"[eoo]\", \"\").replace(\"[cls]\", \"\").replace(\"[boo]\",\"\")\n",
    "    if (\"[bos]\" in generated) and (\"[bos]\" in output):\n",
    "        reference = generated.split(\"[bos]\")[1].strip()\n",
    "        candidate = output.split(\"[bos]\")[1].strip()\n",
    "        gen = extract_ngrams(reference, 4)\n",
    "        act = extract_ngrams(candidate, 4)\n",
    "        # generated vs actual\n",
    "        gen_vs_act.append(len(set(gen))/len(set(act)))\n",
    "        # generated unique vs generated total\n",
    "        gen_vs_gen.append(len(set(gen))/len(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a56146-d0b6-42f9-af48-9fa1d1a8123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(gen_vs_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650fe944-2483-4197-b5ae-93abf70995c0",
   "metadata": {},
   "source": [
    "# Accuracy : BLEU scores for the implication score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176aeb3e-b746-4e8f-b2a6-ab6bf66a8041",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a045a8-60d1-41e4-b57a-3b9e2ec12d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8973fd7-0410-4961-8a5b-9bf914b41a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data within the implication bounds \n",
    "list_preds = merged_df_preds[\"generated\"].tolist()\n",
    "import re\n",
    "total_val = []\n",
    "#split_val = [preds.split(\"[ste]\") for preds in list_preds]\n",
    "for i in range(0, len(list_preds)):\n",
    "    list_preds[i] = list_preds[i].replace(\"<pad>\", \"\").replace(\"[eoo]\", \"\").replace(\"[cls]\", \"\").replace(\"[boo]\",\"\")\n",
    "    real_val_list[i] = real_val_list[i].replace(\"<pad>\", \"\").replace(\"[eoo]\", \"\").replace(\"[cls]\", \"\").replace(\"[boo]\",\"\")\n",
    "    if \"[ste]\" in list_preds[i] and \"[ste]\" in real_val_list[i]:\n",
    "        reference = [list_preds[i].split(\"[ste]\")[1].strip().split(\" \")]\n",
    "        candidate = real_val_list[i].split(\"[ste]\")[1].strip().split(\" \")\n",
    "        twogram = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0), smoothing_function=SmoothingFunction(epsilon=1e-12).method1)\n",
    "        threegram = sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0), smoothing_function=SmoothingFunction(epsilon=1e-12).method1)\n",
    "        total_val.append((twogram + threegram) / 2)\n",
    "# 2 and 3 gram mean for all the data \n",
    "# compare data to actual implications using BLEU score\n",
    "# smoothing method1 - NLTK sentence_bleu add\n",
    "# steps: find where the data that takes implications is in the actual data, compare it with the other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662b934-4b58-4de3-9981-e87146b34d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fcfed-6a44-40f0-9415-6da2e1317d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcbc0c-102f-4dbe-b1f0-b8c49321726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data within the implication bounds \n",
    "list_preds = merged_df_regular[\"generated\"].tolist()\n",
    "import re\n",
    "total_val = []\n",
    "#split_val = [preds.split(\"[ste]\") for preds in list_preds]\n",
    "for i in range(0, len(list_preds)):\n",
    "    list_preds[i] = list_preds[i].replace(\"<pad>\", \"\")\n",
    "    if \"[ste]\" in list_preds[i] and \"[ste]\" in real_val_list[i]:\n",
    "        reference = [list_preds[i].split(\"[ste]\")[1].strip().split(\" \")]\n",
    "        candidate = real_val_list[i].split(\"[ste]\")[1].strip().split(\" \")\n",
    "        twogram = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0), smoothing_function=SmoothingFunction(epsilon=1e-12).method1)\n",
    "        threegram = sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0), smoothing_function=SmoothingFunction(epsilon=1e-12).method1)\n",
    "        total_val.append((twogram + threegram) / 2)\n",
    "# 2 and 3 gram mean for all the data \n",
    "# compare data to actual implications using BLEU score\n",
    "# smoothing method1 - NLTK sentence_bleu add\n",
    "# steps: find where the data that takes implications is in the actual data, compare it with the other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35434962-fa31-435f-bf5e-85839225b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6906fe54-16f7-4c74-a6ef-0bca2b84156c",
   "metadata": {},
   "source": [
    "# Accuracy of 50/50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb9d75-7755-46e2-9bee-6b37dd5cefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv(\"predictions_2_1000.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd7cfe-d222-482d-950b-2f2a01d1f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"Source Text\"] = preds[\"Source Text\"].apply(lambda x: x.replace(\"[boi] \", \"\")).apply(lambda x: x.replace(\" [eoi]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3084d-fe76-43c0-bb26-172389172faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[\"Generated Text\"] = preds[\"Generated Text\"].apply(lambda x: x.replace(\"<pad> \", \"\")).apply(lambda x: x.replace(\" <pad>\", \"\"))\n",
    "preds.columns = [\"post\", \"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a6d9b-90c1-47be-baa0-8fd0fb1bdd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import re\n",
    "list_of_data = []\n",
    "# split on parenthesis\n",
    "for i in range(0, len(generated_predictions)):\n",
    "    list_of_data.append(list(filter(lambda x: x != \"\", [sentence.strip() for sentence in\n",
    "                                                generated_predictions[i].replace(\"<pad>\", '').replace(\"[\", '').replace(\"boo\",'')\n",
    "                                                .replace(\"grp\", '').replace(\"ste\", '').replace(\"eoo\", '')\n",
    "                                                .split(']')])))\n",
    "\n",
    "y_test = pd.read_csv(\"SBIC.v2.agg.dev.csv\", index_col=0)[:1000]\n",
    "y_test\n",
    "\n",
    "merged_df = pd.merge(preds, y_test, on=\"post\")\n",
    "merged_df[\"offensiveYN\"] = merged_df[\"offensiveYN\"].apply(lambda label: 1 if label == 1 else 0)\n",
    "\n",
    "merged_df[\"offYNPredictions\"] = merged_df[\"output\"].apply(lambda label: 1 if \"OffY\" in label else 0)\n",
    "\n",
    "subset_merged_df = merged_df[[\"output\", \"targetMinority\", \"targetCategory\", \"targetStereotype\", \"offensiveYN\"]]\n",
    "subset_merged_df[merged_df.output.str.contains('OffY')].head(50)\n",
    "\n",
    "sum_int = sum(merged_df[\"offYNPredictions\"] == merged_df[\"offensiveYN\"])\n",
    "\n",
    "accuracy_score = sum_int / 1000\n",
    "\n",
    "f1_val = f1_score(y_test_off, list_of_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690d919-ae71-4c8c-ab60-b0039f257fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9d225-e1c9-487b-bf9f-793785ca6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # Qualitative Testing\n",
    "\n",
    "    match = []\n",
    "    for i in range(0, len(list_of_data)):\n",
    "        if list(y_test[\"offensiveYN\"].values)[i] == 0:\n",
    "            list_of_data_val = str(list(list_of_data[1].values)[i])\n",
    "            y_test_val = list(y_test[\"group\"].values)\n",
    "            match.append(any(list_of_data_val in s for s in y_test_val))\n",
    "            \n",
    "    raw_accuracy_group = sum(match) / len(match)\n",
    "\n",
    "\n",
    "    with open(args.output, 'w') as f:\n",
    "        f.write(\"raw accuracy of the Offensive YN: \\n\" + str(accuracy_score))\n",
    "        f.write(\"f1 accuracy score of Offensive YN: \\n\" + str(f1_val))\n",
    "        f.write(\"raw accuracy score of the group tokens: \\n\" + str(raw_accuracy_group))\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c899a3-6ba5-4050-bcc3-464ebfea4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2abe6a7-6935-4892-9b85-82cc89586ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv(\"predictions_5.csv\")\n",
    "predictions_df.drop(predictions_df.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "predictions_df.columns = [\"input\", \"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20fbe0-3b23-4aad-a32f-b849e268bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(predictions_df[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c193f20-8a6d-49c6-98c0-642dd4a209af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed445b5-e886-41ef-a071-1e4c5b9cb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_df = pd.read_csv(\"SBIC.dev.scramble.4.csv\")\n",
    "merged_df = truth_df.merge(predictions_df, on=\"input\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf1aeb-ebf1-4c78-94df-4829ede2acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns=[\"input\", \"output_real\", \"output_model\"]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e186cd-332d-411c-8f16-475b0c979c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_val = merged_df[[\"output_real\", \"output_model\"]].transpose().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44ba6d-944b-4ec7-bd85-43e88d74dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: dict_val[k] for k in list(dict_val)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee6f0c-57eb-4649-a9d7-809433abb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictions_df = pd.read_csv(\"predictions_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d34074ed-0b6b-4f96-87c3-9cb7a6649c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = \"SBIC.trn.scramble.4.csv\"\n",
    "validation_csv = \"SBIC.dev.scramble.4.csv\"\n",
    "\n",
    "\n",
    "training_df = pd.read_csv(training_csv)\n",
    "validation_df = pd.read_csv(validation_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3fb9f3-aa0b-46b7-87bf-e48286bc0c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195147</th>\n",
       "      <td>[boi] [bos] little black kid gets his ass kick...</td>\n",
       "      <td>[boo] [OffY] [ste] black kids are fun to watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164297</th>\n",
       "      <td>[boi] [bos] What’s the difference between a Je...</td>\n",
       "      <td>[boo] [OffY] [grp] jewish folks,terrorism vict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90825</th>\n",
       "      <td>[boi] [bos] I met a Jewish girl today and she ...</td>\n",
       "      <td>[boo] [OffY] [grp] jewish folks [ste] jews had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100960</th>\n",
       "      <td>[boi] [bos] Immigrants Welcome (play book)\\n1....</td>\n",
       "      <td>[boo]  [grp] immigrants [ste] insinuates immig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15073</th>\n",
       "      <td>[boi] [bos] So i was in America and you know s...</td>\n",
       "      <td>[boo]  [grp] mass shooting victims [ste] [\"ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170132</th>\n",
       "      <td>[boi] [bos] Why are all black people fast? All...</td>\n",
       "      <td>[boo] [OffY] [ste] black people run from the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22167</th>\n",
       "      <td>[boi] [bos] What did Jesus say before he died?...</td>\n",
       "      <td>[boo]  [grp] christian folks [ste] [\"christian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45269</th>\n",
       "      <td>[boi] [bos] what do you call a black man with ...</td>\n",
       "      <td>[boo] [OffY] [grp] black folks [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39516</th>\n",
       "      <td>[boi] [bos] how do I cope knowing\\nthat girls ...</td>\n",
       "      <td>[boo] [OffY] [grp] men [ste] [\"is promiscuous\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21219</th>\n",
       "      <td>[boi] [bos] We bring people from shithole coun...</td>\n",
       "      <td>[boo] [OffY] [ste] [\"democrats only get votes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221620</th>\n",
       "      <td>[boi] [bos] white advocacy = hateblack  jewish...</td>\n",
       "      <td>[boo] [OffN] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62264</th>\n",
       "      <td>[boi] [bos] Bitches that smell like dirty laun...</td>\n",
       "      <td>[boo] [OffY] [ste] women are dirty [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213746</th>\n",
       "      <td>[boi] [bos] what phrase do black men always lo...</td>\n",
       "      <td>[boo] [OffN] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107748</th>\n",
       "      <td>[boi] [bos] Maybe you don't like it that much....</td>\n",
       "      <td>[boo]  [grp] women [ste] women can't play cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237081</th>\n",
       "      <td>[boi] [bos] new video ' shows #isis executing ...</td>\n",
       "      <td>[boo] [OffN] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28979</th>\n",
       "      <td>[boi] [bos] What's the worst part of sex When ...</td>\n",
       "      <td>[boo] [OffY] [grp] assault victims [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203539</th>\n",
       "      <td>[boi] [bos] what do you call a black woman who...</td>\n",
       "      <td>[boo] [OffY] [ste] black folks are criminals [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169902</th>\n",
       "      <td>[boi] [bos] Why are Hens similar to Gay couple...</td>\n",
       "      <td>[boo] [OffY] [grp] gay men [ste] gay men are p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>[boi] [bos] RT @shaitaanjerry: This is how u t...</td>\n",
       "      <td>[boo] [OffN] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34436</th>\n",
       "      <td>[boi] [bos] Why is Stevie Wonder always smilin...</td>\n",
       "      <td>[boo] [OffY] [ste] [\"black folks are unhappy\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58379</th>\n",
       "      <td>[boi] [bos] All I want for my birthday is a bi...</td>\n",
       "      <td>[boo] [OffY] [grp] women [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166986</th>\n",
       "      <td>[boi] [bos] When even Thai women give you that...</td>\n",
       "      <td>[boo] [OffY] [grp] asian folks [ste] asian wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148157</th>\n",
       "      <td>[boi] [bos] What does a basketball coach and a...</td>\n",
       "      <td>[boo] [OffY] [grp] black folks [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98368</th>\n",
       "      <td>[boi] [bos] If i fuck a loaf of bread, am i te...</td>\n",
       "      <td>[boo]  [grp] incest victims [ste] trivializes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144179</th>\n",
       "      <td>[boi] [bos] What do you call a redneck burstin...</td>\n",
       "      <td>[boo]  [grp] white folks,white poor people [st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224176</th>\n",
       "      <td>[boi] [bos] muh traditionalism includes going ...</td>\n",
       "      <td>[boo] [OffY] [grp] Conservative males [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157741</th>\n",
       "      <td>[boi] [bos] What's the difference between a bu...</td>\n",
       "      <td>[boo] [OffY] [grp] black folks [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>[boi] [bos] The time span of thousands of year...</td>\n",
       "      <td>[boo] [OffY][ind] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>[boi] [bos] Everyone in a company i used to wo...</td>\n",
       "      <td>[boo] [OffY][ind] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114530</th>\n",
       "      <td>[boi] [bos] Obesity is seen as a growing pande...</td>\n",
       "      <td>[boo] [OffY] [grp] muslim folks,overweight/fat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208283</th>\n",
       "      <td>[boi] [bos] why are black people so much into ...</td>\n",
       "      <td>[boo] [OffY] [ste] like being slaves [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48311</th>\n",
       "      <td>[boi] [bos] \"\"\"Grades don't matter when you're...</td>\n",
       "      <td>[boo] [OffY] [ste] women are meant to be in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129853</th>\n",
       "      <td>[boi] [bos] The women I’m with always seem to ...</td>\n",
       "      <td>[boo] [OffY] [grp] women [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166291</th>\n",
       "      <td>[boi] [bos] What’s the worst part about dating...</td>\n",
       "      <td>[boo]  [grp] asian folks [ste] japanese people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175843</th>\n",
       "      <td>[boi] [bos] Why do homosexuals keep whining ab...</td>\n",
       "      <td>[boo]  [grp] gay men,lesbian women, gay men [s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>[boi] [bos] He's right though mate; clubs are ...</td>\n",
       "      <td>[boo] [OffY][ind] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154523</th>\n",
       "      <td>[boi] [bos] What's a farmer's favourite activi...</td>\n",
       "      <td>[boo] [OffY] [grp] Farmers [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242049</th>\n",
       "      <td>[boi] [bos] i'd adopt these white refugees kid...</td>\n",
       "      <td>[boo] [OffY] [ste] Black and latino/latina peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95146</th>\n",
       "      <td>[boi] [bos] I wonder if this guy still thinks ...</td>\n",
       "      <td>[boo] [OffY] [grp] jewish folks [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143969</th>\n",
       "      <td>[boi] [bos] What do you call a nun being raped...</td>\n",
       "      <td>[boo] [OffY] [grp] assault victims,women [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239341</th>\n",
       "      <td>[boi] [bos] that will happen . the alt-right n...</td>\n",
       "      <td>[boo] [OffN] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239187</th>\n",
       "      <td>[boi] [bos] though all white men &amp; women r not...</td>\n",
       "      <td>[boo]  [grp] Jewish people [ste] Jewish people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111731</th>\n",
       "      <td>[boi] [bos] My wife needs to be renewed, to be...</td>\n",
       "      <td>[boo] [OffY] [grp] black folks [ste] black men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50853</th>\n",
       "      <td>[boi] [bos] #TuckerHighlights 10/16/17:\\n\\n- S...</td>\n",
       "      <td>[boo] [OffY] [grp] liberals [ste] liberals are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167525</th>\n",
       "      <td>[boi] [bos] When you think about it, a woman w...</td>\n",
       "      <td>[boo] [OffY] [grp] women [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114267</th>\n",
       "      <td>[boi] [bos] Now that women can drive in Saudi ...</td>\n",
       "      <td>[boo]  [grp] women [ste] woman are dangerous d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140959</th>\n",
       "      <td>[boi] [bos] What do you call 5 black people ha...</td>\n",
       "      <td>[boo]  [grp] black folks [ste] 2/3 rule is fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242961</th>\n",
       "      <td>[boi] [bos] good read hunter [cls] [eoi]</td>\n",
       "      <td>[boo] [OffN] [eoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78805</th>\n",
       "      <td>[boi] [bos] How do you save a black person fro...</td>\n",
       "      <td>[boo] [OffY] [grp] black folks [ste] should be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134834</th>\n",
       "      <td>[boi] [bos] WHATS THE DIFFERENCE BETWEEN COOKI...</td>\n",
       "      <td>[boo] [OffY] [grp] jewish folks [ste] jews liv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    input  \\\n",
       "195147  [boi] [bos] little black kid gets his ass kick...   \n",
       "164297  [boi] [bos] What’s the difference between a Je...   \n",
       "90825   [boi] [bos] I met a Jewish girl today and she ...   \n",
       "100960  [boi] [bos] Immigrants Welcome (play book)\\n1....   \n",
       "15073   [boi] [bos] So i was in America and you know s...   \n",
       "170132  [boi] [bos] Why are all black people fast? All...   \n",
       "22167   [boi] [bos] What did Jesus say before he died?...   \n",
       "45269   [boi] [bos] what do you call a black man with ...   \n",
       "39516   [boi] [bos] how do I cope knowing\\nthat girls ...   \n",
       "21219   [boi] [bos] We bring people from shithole coun...   \n",
       "221620  [boi] [bos] white advocacy = hateblack  jewish...   \n",
       "62264   [boi] [bos] Bitches that smell like dirty laun...   \n",
       "213746  [boi] [bos] what phrase do black men always lo...   \n",
       "107748  [boi] [bos] Maybe you don't like it that much....   \n",
       "237081  [boi] [bos] new video ' shows #isis executing ...   \n",
       "28979   [boi] [bos] What's the worst part of sex When ...   \n",
       "203539  [boi] [bos] what do you call a black woman who...   \n",
       "169902  [boi] [bos] Why are Hens similar to Gay couple...   \n",
       "12997   [boi] [bos] RT @shaitaanjerry: This is how u t...   \n",
       "34436   [boi] [bos] Why is Stevie Wonder always smilin...   \n",
       "58379   [boi] [bos] All I want for my birthday is a bi...   \n",
       "166986  [boi] [bos] When even Thai women give you that...   \n",
       "148157  [boi] [bos] What does a basketball coach and a...   \n",
       "98368   [boi] [bos] If i fuck a loaf of bread, am i te...   \n",
       "144179  [boi] [bos] What do you call a redneck burstin...   \n",
       "224176  [boi] [bos] muh traditionalism includes going ...   \n",
       "157741  [boi] [bos] What's the difference between a bu...   \n",
       "7568    [boi] [bos] The time span of thousands of year...   \n",
       "6607    [boi] [bos] Everyone in a company i used to wo...   \n",
       "114530  [boi] [bos] Obesity is seen as a growing pande...   \n",
       "208283  [boi] [bos] why are black people so much into ...   \n",
       "48311   [boi] [bos] \"\"\"Grades don't matter when you're...   \n",
       "129853  [boi] [bos] The women I’m with always seem to ...   \n",
       "166291  [boi] [bos] What’s the worst part about dating...   \n",
       "175843  [boi] [bos] Why do homosexuals keep whining ab...   \n",
       "6709    [boi] [bos] He's right though mate; clubs are ...   \n",
       "154523  [boi] [bos] What's a farmer's favourite activi...   \n",
       "242049  [boi] [bos] i'd adopt these white refugees kid...   \n",
       "95146   [boi] [bos] I wonder if this guy still thinks ...   \n",
       "143969  [boi] [bos] What do you call a nun being raped...   \n",
       "239341  [boi] [bos] that will happen . the alt-right n...   \n",
       "239187  [boi] [bos] though all white men & women r not...   \n",
       "111731  [boi] [bos] My wife needs to be renewed, to be...   \n",
       "50853   [boi] [bos] #TuckerHighlights 10/16/17:\\n\\n- S...   \n",
       "167525  [boi] [bos] When you think about it, a woman w...   \n",
       "114267  [boi] [bos] Now that women can drive in Saudi ...   \n",
       "140959  [boi] [bos] What do you call 5 black people ha...   \n",
       "242961           [boi] [bos] good read hunter [cls] [eoi]   \n",
       "78805   [boi] [bos] How do you save a black person fro...   \n",
       "134834  [boi] [bos] WHATS THE DIFFERENCE BETWEEN COOKI...   \n",
       "\n",
       "                                                   output  \n",
       "195147  [boo] [OffY] [ste] black kids are fun to watch...  \n",
       "164297  [boo] [OffY] [grp] jewish folks,terrorism vict...  \n",
       "90825   [boo] [OffY] [grp] jewish folks [ste] jews had...  \n",
       "100960  [boo]  [grp] immigrants [ste] insinuates immig...  \n",
       "15073   [boo]  [grp] mass shooting victims [ste] [\"ame...  \n",
       "170132  [boo] [OffY] [ste] black people run from the p...  \n",
       "22167   [boo]  [grp] christian folks [ste] [\"christian...  \n",
       "45269                [boo] [OffY] [grp] black folks [eoo]  \n",
       "39516   [boo] [OffY] [grp] men [ste] [\"is promiscuous\"...  \n",
       "21219   [boo] [OffY] [ste] [\"democrats only get votes ...  \n",
       "221620                                 [boo] [OffN] [eoo]  \n",
       "62264            [boo] [OffY] [ste] women are dirty [eoo]  \n",
       "213746                                 [boo] [OffN] [eoo]  \n",
       "107748  [boo]  [grp] women [ste] women can't play cert...  \n",
       "237081                                 [boo] [OffN] [eoo]  \n",
       "28979            [boo] [OffY] [grp] assault victims [eoo]  \n",
       "203539  [boo] [OffY] [ste] black folks are criminals [...  \n",
       "169902  [boo] [OffY] [grp] gay men [ste] gay men are p...  \n",
       "12997                                  [boo] [OffN] [eoo]  \n",
       "34436   [boo] [OffY] [ste] [\"black folks are unhappy\",...  \n",
       "58379                      [boo] [OffY] [grp] women [eoo]  \n",
       "166986  [boo] [OffY] [grp] asian folks [ste] asian wom...  \n",
       "148157               [boo] [OffY] [grp] black folks [eoo]  \n",
       "98368   [boo]  [grp] incest victims [ste] trivializes ...  \n",
       "144179  [boo]  [grp] white folks,white poor people [st...  \n",
       "224176        [boo] [OffY] [grp] Conservative males [eoo]  \n",
       "157741               [boo] [OffY] [grp] black folks [eoo]  \n",
       "7568                              [boo] [OffY][ind] [eoo]  \n",
       "6607                              [boo] [OffY][ind] [eoo]  \n",
       "114530  [boo] [OffY] [grp] muslim folks,overweight/fat...  \n",
       "208283         [boo] [OffY] [ste] like being slaves [eoo]  \n",
       "48311   [boo] [OffY] [ste] women are meant to be in th...  \n",
       "129853                     [boo] [OffY] [grp] women [eoo]  \n",
       "166291  [boo]  [grp] asian folks [ste] japanese people...  \n",
       "175843  [boo]  [grp] gay men,lesbian women, gay men [s...  \n",
       "6709                              [boo] [OffY][ind] [eoo]  \n",
       "154523                   [boo] [OffY] [grp] Farmers [eoo]  \n",
       "242049  [boo] [OffY] [ste] Black and latino/latina peo...  \n",
       "95146               [boo] [OffY] [grp] jewish folks [eoo]  \n",
       "143969     [boo] [OffY] [grp] assault victims,women [eoo]  \n",
       "239341                                 [boo] [OffN] [eoo]  \n",
       "239187  [boo]  [grp] Jewish people [ste] Jewish people...  \n",
       "111731  [boo] [OffY] [grp] black folks [ste] black men...  \n",
       "50853   [boo] [OffY] [grp] liberals [ste] liberals are...  \n",
       "167525                     [boo] [OffY] [grp] women [eoo]  \n",
       "114267  [boo]  [grp] women [ste] woman are dangerous d...  \n",
       "140959  [boo]  [grp] black folks [ste] 2/3 rule is fun...  \n",
       "242961                                 [boo] [OffN] [eoo]  \n",
       "78805   [boo] [OffY] [grp] black folks [ste] should be...  \n",
       "134834  [boo] [OffY] [grp] jewish folks [ste] jews liv...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.sample(frac=1.0)[:50].to_csv(\"50_examples.4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054a3d3-97fc-444a-b1b1-e331827cd7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "278e4ec3-5d52-4c75-921f-0d4fd21b6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_return(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b5aa932-035c-4cbb-bcf0-82a646f01eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>group</th>\n",
       "      <th>implications</th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 10,000 arrests for child trafficking sinc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSA\\nY'all should stay away from stupidslutscl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PSA: Remember to share the Atomic Blackpill on...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Partly Cloudy today! With a high of 16C.and a ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Party bus going to LA live at this bar/bowling...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10181</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>[\"jewish folks\"]</td>\n",
       "      <td>died in the holocaust.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10182</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>[\"jewish folks\"]</td>\n",
       "      <td>have a troubled past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10183</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>[\"jewish folks\"]</td>\n",
       "      <td>jews deserved to be burned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10184</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>[\"jewish folks\"]</td>\n",
       "      <td>making a joke about the holocaust.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10185</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>[\"jewish folks\"]</td>\n",
       "      <td>were the subject of extermination</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post             group  \\\n",
       "0      Over 10,000 arrests for child trafficking sinc...                []   \n",
       "1      PSA\\nY'all should stay away from stupidslutscl...                []   \n",
       "2      PSA: Remember to share the Atomic Blackpill on...                []   \n",
       "3      Partly Cloudy today! With a high of 16C.and a ...                []   \n",
       "4      Party bus going to LA live at this bar/bowling...                []   \n",
       "...                                                  ...               ...   \n",
       "10181  ♪ &#9835; ♬ believe it or not i 'm gassing the...  [\"jewish folks\"]   \n",
       "10182  ♪ &#9835; ♬ believe it or not i 'm gassing the...  [\"jewish folks\"]   \n",
       "10183  ♪ &#9835; ♬ believe it or not i 'm gassing the...  [\"jewish folks\"]   \n",
       "10184  ♪ &#9835; ♬ believe it or not i 'm gassing the...  [\"jewish folks\"]   \n",
       "10185  ♪ &#9835; ♬ believe it or not i 'm gassing the...  [\"jewish folks\"]   \n",
       "\n",
       "                             implications  whoTarget offensiveYN  \n",
       "0                                      []        NaN      [OffN]  \n",
       "1                                      []        0.0      [OffN]  \n",
       "2                                      []        0.0      [OffN]  \n",
       "3                                      []        NaN      [OffN]  \n",
       "4                                      []        NaN      [OffN]  \n",
       "...                                   ...        ...         ...  \n",
       "10181              died in the holocaust.        1.0      [OffY]  \n",
       "10182                have a troubled past        1.0      [OffY]  \n",
       "10183          jews deserved to be burned        1.0      [OffY]  \n",
       "10184  making a joke about the holocaust.        1.0      [OffY]  \n",
       "10185   were the subject of extermination        1.0      [OffY]  \n",
       "\n",
       "[10186 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "i = 0;\n",
    "original_len = len(dev_csv)\n",
    "while i < original_len:\n",
    "    list_val = literal_return(dev_csv[\"implications\"].tolist()[i])\n",
    "    if (list_val != None and len(list_val) != 0):\n",
    "        s=dev_csv.iloc[[i],] # pick the row you want to do repeat\n",
    "        s=s.reindex(s.index.repeat(len(list_val)))# repeat the row by the giving number \n",
    "        s.loc[:,'implications']=list_val # change the value\n",
    "        dev_csv=pd.concat([dev_csv,s]) #append to the original df \n",
    "        dev_csv.reset_index(drop=True, inplace=True)\n",
    "    i = i + 1\n",
    "\n",
    "#do final pass over the implications and get rid of list format\n",
    "i = 0;\n",
    "while i < original_len:\n",
    "    if \"[\" in dev_csv[\"implications\"].tolist()[i]:\n",
    "        dev_csv.drop(index=i, axis=0, inplace=True)\n",
    "        dev_csv.reset_index()\n",
    "    i = i + 1\n",
    "\n",
    "dev_csv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3edea5f3-36bb-46eb-83a5-960b9f441284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>group</th>\n",
       "      <th>implications</th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 10,000 arrests for child trafficking sinc...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSA\\nY'all should stay away from stupidslutscl...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PSA: Remember to share the Atomic Blackpill on...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Partly Cloudy today! With a high of 16C.and a ...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Party bus going to LA live at this bar/bowling...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10181</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>died in the holocaust.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10182</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>have a troubled past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10183</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>jews deserved to be burned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10184</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>making a joke about the holocaust.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10185</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>were the subject of extermination</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post         group  \\\n",
       "0      Over 10,000 arrests for child trafficking sinc...                 \n",
       "1      PSA\\nY'all should stay away from stupidslutscl...                 \n",
       "2      PSA: Remember to share the Atomic Blackpill on...                 \n",
       "3      Partly Cloudy today! With a high of 16C.and a ...                 \n",
       "4      Party bus going to LA live at this bar/bowling...                 \n",
       "...                                                  ...           ...   \n",
       "10181  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "10182  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "10183  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "10184  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "10185  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "\n",
       "                             implications  whoTarget offensiveYN  \n",
       "0                                      []        NaN      [OffN]  \n",
       "1                                      []        0.0      [OffN]  \n",
       "2                                      []        0.0      [OffN]  \n",
       "3                                      []        NaN      [OffN]  \n",
       "4                                      []        NaN      [OffN]  \n",
       "...                                   ...        ...         ...  \n",
       "10181              died in the holocaust.        1.0      [OffY]  \n",
       "10182                have a troubled past        1.0      [OffY]  \n",
       "10183          jews deserved to be burned        1.0      [OffY]  \n",
       "10184  making a joke about the holocaust.        1.0      [OffY]  \n",
       "10185   were the subject of extermination        1.0      [OffY]  \n",
       "\n",
       "[10186 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_group = []\n",
    "for i in range(0, len(dev_csv)):\n",
    "    list_group.append(\",\".join(map(str, literal_return(dev_csv.iloc[[i]][\"group\"].values[0]))))\n",
    "    #list_group.append(\",\".join(map(str, literal_return(dev_csv.iloc[[i]][\"group\"]) if not None)))\n",
    "    \n",
    "dev_csv[\"group\"] = list_group\n",
    "dev_csv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ebd918ea-bb6b-4f79-ac11-1676aa884830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post', 'group', 'implications', 'whoTarget', 'offensiveYN'], dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "066d526d-9ad5-457f-8faa-35d7ed110e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>group</th>\n",
       "      <th>implications</th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nelly got all the hoes singin lol</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nelson snaps me a pic of him in a cocoon sleep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neocels\\n..is the term to describe normies who...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nerd followers: I'm monitoring hashtag/mention...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Net neutrality is pretty irrelevant when a han...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58655</th>\n",
       "      <td>⁠Why do wh*te people like to play hockey?  It’...</td>\n",
       "      <td>[\"black folks\", \"white folks\"]</td>\n",
       "      <td>makes light of racial tension with police</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58656</th>\n",
       "      <td>🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n</td>\n",
       "      <td>[\"muslim folks\"]</td>\n",
       "      <td>muslims are terrorists</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58657</th>\n",
       "      <td>🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n</td>\n",
       "      <td>[\"muslim folks\"]</td>\n",
       "      <td>muslims like bombs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58658</th>\n",
       "      <td>🚨BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>[\"immigrants\"]</td>\n",
       "      <td>immigrants are criminals</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58659</th>\n",
       "      <td>🚨BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>[\"immigrants\"]</td>\n",
       "      <td>immigrants are murderers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58660 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post  \\\n",
       "0                      Nelly got all the hoes singin lol   \n",
       "1      Nelson snaps me a pic of him in a cocoon sleep...   \n",
       "2      Neocels\\n..is the term to describe normies who...   \n",
       "3      Nerd followers: I'm monitoring hashtag/mention...   \n",
       "4      Net neutrality is pretty irrelevant when a han...   \n",
       "...                                                  ...   \n",
       "58655  ⁠Why do wh*te people like to play hockey?  It’...   \n",
       "58656           🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n   \n",
       "58657           🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n   \n",
       "58658  🚨BREAKING: illegal alien 5x deported on 7 felo...   \n",
       "58659  🚨BREAKING: illegal alien 5x deported on 7 felo...   \n",
       "\n",
       "                                group  \\\n",
       "0                                  []   \n",
       "1                                  []   \n",
       "2                                  []   \n",
       "3                                  []   \n",
       "4                                  []   \n",
       "...                               ...   \n",
       "58655  [\"black folks\", \"white folks\"]   \n",
       "58656                [\"muslim folks\"]   \n",
       "58657                [\"muslim folks\"]   \n",
       "58658                  [\"immigrants\"]   \n",
       "58659                  [\"immigrants\"]   \n",
       "\n",
       "                                    implications  whoTarget offensiveYN  \n",
       "0                                             []        0.0      [OffN]  \n",
       "1                                             []        0.0      [OffN]  \n",
       "2                                             []        0.0      [OffN]  \n",
       "3                                             []        NaN      [OffN]  \n",
       "4                                             []        0.0      [OffN]  \n",
       "...                                          ...        ...         ...  \n",
       "58655  makes light of racial tension with police        1.0      [OffY]  \n",
       "58656                     muslims are terrorists        1.0      [OffY]  \n",
       "58657                         muslims like bombs        1.0      [OffY]  \n",
       "58658                   immigrants are criminals        1.0      [OffY]  \n",
       "58659                   immigrants are murderers        1.0      [OffY]  \n",
       "\n",
       "[58660 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "i = 0;\n",
    "original_len = len(training_csv)\n",
    "while i < original_len:\n",
    "    list_val = literal_return(training_csv[\"implications\"].tolist()[i])\n",
    "    if (list_val != None and len(list_val) != 0):\n",
    "        s=training_csv.iloc[[i],] # pick the row you want to do repeat\n",
    "        s=s.reindex(s.index.repeat(len(list_val)))# repeat the row by the giving number \n",
    "        s.loc[:,'implications']=list_val # change the value\n",
    "        training_csv=pd.concat([training_csv,s]) #append to the original df \n",
    "        training_csv.reset_index(drop=True, inplace=True)\n",
    "    i = i + 1\n",
    "\n",
    "#do final pass over the implications and get rid of list format\n",
    "i = 0;\n",
    "while i < original_len:\n",
    "    if \"[\" in training_csv[\"implications\"].tolist()[i]:\n",
    "        training_csv.drop(index=i, axis=0, inplace=True)\n",
    "        training_csv.reset_index()\n",
    "    i = i + 1\n",
    "\n",
    "training_csv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c21136d-c90e-440d-ac01-b1c2e093f45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>group</th>\n",
       "      <th>implications</th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nelly got all the hoes singin lol</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nelson snaps me a pic of him in a cocoon sleep...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neocels\\n..is the term to describe normies who...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nerd followers: I'm monitoring hashtag/mention...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Net neutrality is pretty irrelevant when a han...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58655</th>\n",
       "      <td>⁠Why do wh*te people like to play hockey?  It’...</td>\n",
       "      <td>black folks,white folks</td>\n",
       "      <td>makes light of racial tension with police</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58656</th>\n",
       "      <td>🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n</td>\n",
       "      <td>muslim folks</td>\n",
       "      <td>muslims are terrorists</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58657</th>\n",
       "      <td>🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n</td>\n",
       "      <td>muslim folks</td>\n",
       "      <td>muslims like bombs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58658</th>\n",
       "      <td>🚨BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>immigrants</td>\n",
       "      <td>immigrants are criminals</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58659</th>\n",
       "      <td>🚨BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>immigrants</td>\n",
       "      <td>immigrants are murderers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58660 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post  \\\n",
       "0                      Nelly got all the hoes singin lol   \n",
       "1      Nelson snaps me a pic of him in a cocoon sleep...   \n",
       "2      Neocels\\n..is the term to describe normies who...   \n",
       "3      Nerd followers: I'm monitoring hashtag/mention...   \n",
       "4      Net neutrality is pretty irrelevant when a han...   \n",
       "...                                                  ...   \n",
       "58655  ⁠Why do wh*te people like to play hockey?  It’...   \n",
       "58656           🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n   \n",
       "58657           🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n   \n",
       "58658  🚨BREAKING: illegal alien 5x deported on 7 felo...   \n",
       "58659  🚨BREAKING: illegal alien 5x deported on 7 felo...   \n",
       "\n",
       "                         group                               implications  \\\n",
       "0                                                                      []   \n",
       "1                                                                      []   \n",
       "2                                                                      []   \n",
       "3                                                                      []   \n",
       "4                                                                      []   \n",
       "...                        ...                                        ...   \n",
       "58655  black folks,white folks  makes light of racial tension with police   \n",
       "58656             muslim folks                     muslims are terrorists   \n",
       "58657             muslim folks                         muslims like bombs   \n",
       "58658               immigrants                   immigrants are criminals   \n",
       "58659               immigrants                   immigrants are murderers   \n",
       "\n",
       "       whoTarget offensiveYN  \n",
       "0            0.0      [OffN]  \n",
       "1            0.0      [OffN]  \n",
       "2            0.0      [OffN]  \n",
       "3            NaN      [OffN]  \n",
       "4            0.0      [OffN]  \n",
       "...          ...         ...  \n",
       "58655        1.0      [OffY]  \n",
       "58656        1.0      [OffY]  \n",
       "58657        1.0      [OffY]  \n",
       "58658        1.0      [OffY]  \n",
       "58659        1.0      [OffY]  \n",
       "\n",
       "[58660 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_group = []\n",
    "for i in range(0, len(training_csv)):\n",
    "    list_group.append(\",\".join(map(str, literal_return(training_csv.iloc[[i]][\"group\"].values[0]))))\n",
    "    #list_group.append(\",\".join(map(str, literal_return(training_csv.iloc[[i]][\"group\"]) if not None)))\n",
    "    \n",
    "training_csv[\"group\"] = list_group\n",
    "training_csv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc8ba967-b9a2-4a0a-ac58-67ddba94a12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>group</th>\n",
       "      <th>implications</th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17712</th>\n",
       "      <td>Nelly got all the hoes singin lol</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17713</th>\n",
       "      <td>Nelson snaps me a pic of him in a cocoon sleep...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17714</th>\n",
       "      <td>Neocels\\n..is the term to describe normies who...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17715</th>\n",
       "      <td>Nerd followers: I'm monitoring hashtag/mention...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17716</th>\n",
       "      <td>Net neutrality is pretty irrelevant when a han...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76367</th>\n",
       "      <td>⁠Why do wh*te people like to play hockey?  It’...</td>\n",
       "      <td>black folks,white folks</td>\n",
       "      <td>makes light of racial tension with police</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76368</th>\n",
       "      <td>🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n</td>\n",
       "      <td>muslim folks</td>\n",
       "      <td>muslims are terrorists</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76369</th>\n",
       "      <td>🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n</td>\n",
       "      <td>muslim folks</td>\n",
       "      <td>muslims like bombs</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76370</th>\n",
       "      <td>🚨BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>immigrants</td>\n",
       "      <td>immigrants are criminals</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76371</th>\n",
       "      <td>🚨BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>immigrants</td>\n",
       "      <td>immigrants are murderers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58660 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post  \\\n",
       "17712                  Nelly got all the hoes singin lol   \n",
       "17713  Nelson snaps me a pic of him in a cocoon sleep...   \n",
       "17714  Neocels\\n..is the term to describe normies who...   \n",
       "17715  Nerd followers: I'm monitoring hashtag/mention...   \n",
       "17716  Net neutrality is pretty irrelevant when a han...   \n",
       "...                                                  ...   \n",
       "76367  ⁠Why do wh*te people like to play hockey?  It’...   \n",
       "76368           🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n   \n",
       "76369           🏢🏢 👳🏽‍♂️✈️➡️➡️🏢🏢➡️➡️💥💥➡️➡️🤷🏻‍♂️🤷🏻‍♂️\\n\\n   \n",
       "76370  🚨BREAKING: illegal alien 5x deported on 7 felo...   \n",
       "76371  🚨BREAKING: illegal alien 5x deported on 7 felo...   \n",
       "\n",
       "                         group                               implications  \\\n",
       "17712                                                                  []   \n",
       "17713                                                                  []   \n",
       "17714                                                                  []   \n",
       "17715                                                                  []   \n",
       "17716                                                                  []   \n",
       "...                        ...                                        ...   \n",
       "76367  black folks,white folks  makes light of racial tension with police   \n",
       "76368             muslim folks                     muslims are terrorists   \n",
       "76369             muslim folks                         muslims like bombs   \n",
       "76370               immigrants                   immigrants are criminals   \n",
       "76371               immigrants                   immigrants are murderers   \n",
       "\n",
       "       whoTarget offensiveYN  \n",
       "17712        0.0      [OffN]  \n",
       "17713        0.0      [OffN]  \n",
       "17714        0.0      [OffN]  \n",
       "17715        NaN      [OffN]  \n",
       "17716        0.0      [OffN]  \n",
       "...          ...         ...  \n",
       "76367        1.0      [OffY]  \n",
       "76368        1.0      [OffY]  \n",
       "76369        1.0      [OffY]  \n",
       "76370        1.0      [OffY]  \n",
       "76371        1.0      [OffY]  \n",
       "\n",
       "[58660 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "957397fd-9c0e-4081-8ea1-51445972435c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>implications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19712</th>\n",
       "      <td>[\"fat folks are animals/hippos\", \"physically d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19713</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19714</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19715</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19716</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19807</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19808</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19809</th>\n",
       "      <td>[\"are niggers\", \"black people are dumb\", \"blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19810</th>\n",
       "      <td>[\"ugly people shouldn't be taken seriously\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19811</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            implications\n",
       "19712  [\"fat folks are animals/hippos\", \"physically d...\n",
       "19713                                                 []\n",
       "19714                                                 []\n",
       "19715                                                 []\n",
       "19716                                                 []\n",
       "...                                                  ...\n",
       "19807                                                 []\n",
       "19808                                                 []\n",
       "19809  [\"are niggers\", \"black people are dumb\", \"blac...\n",
       "19810  [\"ugly people shouldn't be taken seriously\", \"...\n",
       "19811                                                 []\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_csv[[\"implications\"]].dropna()[2000:2100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac6c6cb-96d6-4db1-8145-e38bb0caca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>group</th>\n",
       "      <th>implications</th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>Over 10,000 arrests for child trafficking sinc...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>PSA\\nY'all should stay away from stupidslutscl...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>PSA: Remember to share the Atomic Blackpill on...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>Partly Cloudy today! With a high of 16C.and a ...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>Party bus going to LA live at this bar/bowling...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[OffN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12514</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>died in the holocaust.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12515</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>have a troubled past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12516</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>jews deserved to be burned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12517</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>making a joke about the holocaust.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12518</th>\n",
       "      <td>♪ &amp;#9835; ♬ believe it or not i 'm gassing the...</td>\n",
       "      <td>jewish folks</td>\n",
       "      <td>were the subject of extermination</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[OffY]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post         group  \\\n",
       "2333   Over 10,000 arrests for child trafficking sinc...                 \n",
       "2334   PSA\\nY'all should stay away from stupidslutscl...                 \n",
       "2335   PSA: Remember to share the Atomic Blackpill on...                 \n",
       "2336   Partly Cloudy today! With a high of 16C.and a ...                 \n",
       "2337   Party bus going to LA live at this bar/bowling...                 \n",
       "...                                                  ...           ...   \n",
       "12514  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "12515  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "12516  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "12517  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "12518  ♪ &#9835; ♬ believe it or not i 'm gassing the...  jewish folks   \n",
       "\n",
       "                             implications  whoTarget offensiveYN  \n",
       "2333                                   []        NaN      [OffN]  \n",
       "2334                                   []        0.0      [OffN]  \n",
       "2335                                   []        0.0      [OffN]  \n",
       "2336                                   []        NaN      [OffN]  \n",
       "2337                                   []        NaN      [OffN]  \n",
       "...                                   ...        ...         ...  \n",
       "12514              died in the holocaust.        1.0      [OffY]  \n",
       "12515                have a troubled past        1.0      [OffY]  \n",
       "12516          jews deserved to be burned        1.0      [OffY]  \n",
       "12517  making a joke about the holocaust.        1.0      [OffY]  \n",
       "12518   were the subject of extermination        1.0      [OffY]  \n",
       "\n",
       "[10186 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
